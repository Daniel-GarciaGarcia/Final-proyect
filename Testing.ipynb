{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly\n",
    "from collections import Counter\n",
    "import re\n",
    "import string \n",
    "\n",
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.porter import * \n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= pd.read_csv(\"./Outputs/FilteredDataSet.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['date',\n",
       " 'user_name',\n",
       " 'user_loc',\n",
       " 'message',\n",
       " 'full_name',\n",
       " 'country',\n",
       " 'country_code',\n",
       " 'geo_code',\n",
       " 'longitud_mensaje',\n",
       " 'palabras',\n",
       " 'refinado']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_loc</th>\n",
       "      <th>message</th>\n",
       "      <th>full_name</th>\n",
       "      <th>country</th>\n",
       "      <th>country_code</th>\n",
       "      <th>geo_code</th>\n",
       "      <th>longitud_mensaje</th>\n",
       "      <th>palabras</th>\n",
       "      <th>refinado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-10-10 11:41:36</td>\n",
       "      <td>susanha77835097</td>\n",
       "      <td>Florida, USA</td>\n",
       "      <td>@blossomingabyss @JoeBiden He filled his pocke...</td>\n",
       "      <td>Sunny Isles Beach, FL</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>[-80.125071  25.92906 ]</td>\n",
       "      <td>140</td>\n",
       "      <td>18</td>\n",
       "      <td>['filled', 'pocketskids', 'familyharris', 'unq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-10-10 11:19:05</td>\n",
       "      <td>tomborelli</td>\n",
       "      <td>Greenwich, CT</td>\n",
       "      <td>Supporting @JoeBiden means packing the Supreme...</td>\n",
       "      <td>Greenwich, CT</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>[-73.63941   41.050217]</td>\n",
       "      <td>144</td>\n",
       "      <td>17</td>\n",
       "      <td>['supporting', 'means', 'packing', 'supreme', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-10-10 09:39:10</td>\n",
       "      <td>John_Di_Lemme</td>\n",
       "      <td>(561) 847-3467</td>\n",
       "      <td>@ABC13News @realDonaldTrump @JoeBiden Nancy Pe...</td>\n",
       "      <td>West Palm Beach, FL</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>[-80.12262   26.721896]</td>\n",
       "      <td>133</td>\n",
       "      <td>15</td>\n",
       "      <td>['nancy', 'pelosi', 'nuts', 'joe', 'biden', 'k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-10-10 08:39:14</td>\n",
       "      <td>Parnell_100</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>@JoeBiden There is NO STOPPING this AMERICAN T...</td>\n",
       "      <td>Belfast, Northern Ireland</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>GB</td>\n",
       "      <td>[-5.928413 54.595869]</td>\n",
       "      <td>140</td>\n",
       "      <td>23</td>\n",
       "      <td>['stopping', 'american', 'trinity', 'train', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-10-10 07:18:33</td>\n",
       "      <td>sqlblues</td>\n",
       "      <td>Weston-super-Mare, England</td>\n",
       "      <td>@FenrirWolf26 @Stanhope2011VJ Britons have als...</td>\n",
       "      <td>Weston-super-Mare, England</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>GB</td>\n",
       "      <td>[-2.94513  51.346796]</td>\n",
       "      <td>139</td>\n",
       "      <td>17</td>\n",
       "      <td>['britons', 'also', 'pumped', 'relentless', 'd...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date        user_name                    user_loc  \\\n",
       "0  2020-10-10 11:41:36  susanha77835097                Florida, USA   \n",
       "1  2020-10-10 11:19:05       tomborelli               Greenwich, CT   \n",
       "2  2020-10-10 09:39:10    John_Di_Lemme              (561) 847-3467   \n",
       "3  2020-10-10 08:39:14      Parnell_100              United Kingdom   \n",
       "4  2020-10-10 07:18:33         sqlblues  Weston-super-Mare, England   \n",
       "\n",
       "                                             message  \\\n",
       "0  @blossomingabyss @JoeBiden He filled his pocke...   \n",
       "1  Supporting @JoeBiden means packing the Supreme...   \n",
       "2  @ABC13News @realDonaldTrump @JoeBiden Nancy Pe...   \n",
       "3  @JoeBiden There is NO STOPPING this AMERICAN T...   \n",
       "4  @FenrirWolf26 @Stanhope2011VJ Britons have als...   \n",
       "\n",
       "                    full_name         country country_code  \\\n",
       "0       Sunny Isles Beach, FL   United States           US   \n",
       "1               Greenwich, CT   United States           US   \n",
       "2         West Palm Beach, FL   United States           US   \n",
       "3   Belfast, Northern Ireland  United Kingdom           GB   \n",
       "4  Weston-super-Mare, England  United Kingdom           GB   \n",
       "\n",
       "                  geo_code  longitud_mensaje  palabras  \\\n",
       "0  [-80.125071  25.92906 ]               140        18   \n",
       "1  [-73.63941   41.050217]               144        17   \n",
       "2  [-80.12262   26.721896]               133        15   \n",
       "3    [-5.928413 54.595869]               140        23   \n",
       "4    [-2.94513  51.346796]               139        17   \n",
       "\n",
       "                                            refinado  \n",
       "0  ['filled', 'pocketskids', 'familyharris', 'unq...  \n",
       "1  ['supporting', 'means', 'packing', 'supreme', ...  \n",
       "2  ['nancy', 'pelosi', 'nuts', 'joe', 'biden', 'k...  \n",
       "3  ['stopping', 'american', 'trinity', 'train', '...  \n",
       "4  ['britons', 'also', 'pumped', 'relentless', 'd...  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet= test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = df_tweet['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/danielgarcia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def processTweet(tweet):\n",
    "    \"\"\"\n",
    "    Takes in a string of text, then performs the following:\n",
    "    1. Removes links, special characters and other bulk cleaning\n",
    "    2. Returns a list of the tidy text\n",
    "    \"\"\"\n",
    "    # Remove HTML special entities (e.g. &amp;)\n",
    "    tweet = re.sub(r'\\&\\w*;', '', tweet)\n",
    "    #Convert @username to AT_USER\n",
    "    tweet = re.sub('@[^\\s]+','',tweet)\n",
    "    # Remove tickers\n",
    "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
    "    # To lowercase\n",
    "    tweet = tweet.lower()\n",
    "    # Remove hyperlinks\n",
    "    tweet = re.sub(r'https?:\\/\\/.*\\/\\w*', '', tweet)\n",
    "    # Remove hashtags\n",
    "    tweet = re.sub(r'#\\w*', '', tweet)\n",
    "    # Remove words with 2 or fewer letters\n",
    "    tweet = re.sub(r'\\b\\w{1,2}\\b', '', tweet)\n",
    "    # Remove whitespace (including new line characters)\n",
    "    tweet = re.sub(r'\\s\\s+', ' ', tweet)\n",
    "    # Remove single space remaining at the front of the tweet.\n",
    "    tweet = tweet.lstrip(' ') \n",
    "    # Remove characters beyond Basic Multilingual Plane (BMP) of Unicode:\n",
    "    tweet = ''.join(c for c in tweet if c <= '\\uFFFF') \n",
    "    return tweet\n",
    "# tokenize helper function\n",
    "def text_process(tweet):\n",
    "    \"\"\"\n",
    "    Takes in a string of text, then performs the following:\n",
    "    1. Remove all punctuation\n",
    "    2. Remove all stopwords\n",
    "    3. Returns a list of the cleaned text\n",
    "    \"\"\"\n",
    "    # Check characters to see if they are in punctuation\n",
    "    nopunc = [char for char in list(tweet) if char not in string.punctuation]\n",
    "\n",
    "    # Join the characters again to form the string.\n",
    "    nopunc = ''.join(nopunc)\n",
    "    \n",
    "    # Now just remove any stopwords\n",
    "    return [word for word in nopunc.lower().split() if word.lower() not in stopwords.words('english')]\n",
    "\n",
    "# Lexicon normalisation with Stemming \n",
    "def stemming(tokens):\n",
    "  \"\"\"\n",
    "  Takes in a string of text, then performs the following:\n",
    "  1. Replace words for its root based on orter Stemmer rule.\n",
    "  2. Returns normalised text\n",
    "   \"\"\"\n",
    "  stemmer = PorterStemmer()\n",
    "  x = [stemmer.stem(w) for w in tokens]\n",
    "   \n",
    "  return ' '.join(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    filled his pocketskids familyharris unqualifie...\n",
      "1    supporting means packing the supreme court lib...\n",
      "2    nancy pelosi nuts! joe biden and kamala harris...\n",
      "3    there stopping this american trinity train - b...\n",
      "4    britons have also been pumped relentless diet ...\n",
      "Name: mensajeprocesado, dtype: object\n",
      "0    filled his pocketskids familyharris unqualifie...\n",
      "1    supporting means packing the supreme court lib...\n",
      "2    nancy pelosi nuts  joe biden and kamala harris...\n",
      "3    there stopping this american trinity train   b...\n",
      "4    britons have also been pumped relentless diet ...\n",
      "Name: mensajeprocesado, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing\n",
    "df_tweet['mensajeprocesado'] = df_tweet['message'].apply(processTweet)\n",
    "print(df_tweet.mensajeprocesado.head())\n",
    "# Double check\n",
    "df_tweet['mensajeprocesado'] = df_tweet['mensajeprocesado'].str.replace(\"[^a-zA-Z#]\", \" \") \n",
    "print(df_tweet.mensajeprocesado.head())\n",
    "# tokenize tidy_tweet column and create a column for tokens\n",
    "test['tokens'] = df_tweet['refinado'].copy() # tokenize\n",
    "\n",
    "# Normalisation\n",
    "stemmer = PorterStemmer() \n",
    "normalized_tweet = df_tweet['mensajeprocesado'].apply(lambda x: [stemmer.stem(i) for i in x]) # stemming\n",
    "\n",
    "for i in range(len(normalized_tweet)):\n",
    "    normalized_tweet[i] = ''.join(normalized_tweet[i])    \n",
    "df_tweet['mensajeprocesado'] = normalized_tweet\n",
    "\n",
    "df_tweet.drop(df_tweet.filter(regex=\"Unname\"),axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = df_tweet['message'].apply(processTweet)\n",
    "nb_words = 10000  \n",
    "tk = Tokenizer(num_words=nb_words) #tokenize\n",
    "tk.fit_on_texts(tweet) #tokenize\n",
    "\n",
    "# format your input for the neural net\n",
    "tweets_seq = tk.texts_to_sequences(tweet) # integer encode\n",
    "tweet_array = pad_sequences(tweets_seq, # good to use length it was trained on\n",
    "                            maxlen=39) # Convert to 2-D Numpy array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"modeloKerasreg\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 28, 128)           1280000   \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 28, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 200)               263200    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 603       \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 1,543,803\n",
      "Trainable params: 1,543,803\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "LSTM_model = load_model('./models/LSTM_model.h5')\n",
    "LSTM_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 28) for input Tensor(\"embedding_3_input_5:0\", shape=(None, 28), dtype=float32), but it was called on an input with incompatible shape (2504, 39).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2504, 13)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = len(tweet_array)\n",
    "\n",
    "# for human-friendly printing\n",
    "labels = ['negative', 'positive']\n",
    "\n",
    "# Predict and get output from the model\n",
    "pred= LSTM_model.predict_classes(tweet_array, batch_size)\n",
    "\n",
    "# append predictions to dataframe\n",
    "df_tweet['predictions'] = pred\n",
    "df_tweet.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_loc</th>\n",
       "      <th>message</th>\n",
       "      <th>full_name</th>\n",
       "      <th>country</th>\n",
       "      <th>country_code</th>\n",
       "      <th>geo_code</th>\n",
       "      <th>longitud_mensaje</th>\n",
       "      <th>palabras</th>\n",
       "      <th>refinado</th>\n",
       "      <th>predictions</th>\n",
       "      <th>mensajeprocesado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-10-10 11:41:36</td>\n",
       "      <td>susanha77835097</td>\n",
       "      <td>Florida, USA</td>\n",
       "      <td>@blossomingabyss @JoeBiden He filled his pocke...</td>\n",
       "      <td>Sunny Isles Beach, FL</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>[-80.125071  25.92906 ]</td>\n",
       "      <td>140</td>\n",
       "      <td>18</td>\n",
       "      <td>['filled', 'pocketskids', 'familyharris', 'unq...</td>\n",
       "      <td>2</td>\n",
       "      <td>filled his pocketskids familyharris unqualifie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-10-10 08:39:14</td>\n",
       "      <td>Parnell_100</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>@JoeBiden There is NO STOPPING this AMERICAN T...</td>\n",
       "      <td>Belfast, Northern Ireland</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>GB</td>\n",
       "      <td>[-5.928413 54.595869]</td>\n",
       "      <td>140</td>\n",
       "      <td>23</td>\n",
       "      <td>['stopping', 'american', 'trinity', 'train', '...</td>\n",
       "      <td>2</td>\n",
       "      <td>there stopping this american trinity train   b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-10-10 05:19:12</td>\n",
       "      <td>cyn507</td>\n",
       "      <td>Philadelphia, PA</td>\n",
       "      <td>Looks like @realDonaldTrump is running scared....</td>\n",
       "      <td>Philadelphia, PA</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>[-75.117998  40.004866]</td>\n",
       "      <td>140</td>\n",
       "      <td>20</td>\n",
       "      <td>['looks', 'like', 'running', 'scared', 'bag', ...</td>\n",
       "      <td>2</td>\n",
       "      <td>looks like running scared  his bag tricks does...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2020-10-10 01:22:40</td>\n",
       "      <td>KLehneiswxguy</td>\n",
       "      <td>United States</td>\n",
       "      <td>@NBSaphierMD @JoeBiden Because Joe Biden is ch...</td>\n",
       "      <td>Beavercreek, OH</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>[-84.047553  39.727936]</td>\n",
       "      <td>139</td>\n",
       "      <td>20</td>\n",
       "      <td>['joe', 'biden', 'chickening', 'wanted', 'othe...</td>\n",
       "      <td>2</td>\n",
       "      <td>because joe biden chickening out  wanted other...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2020-10-10 00:29:13</td>\n",
       "      <td>Sp8d</td>\n",
       "      <td>Houston, TX</td>\n",
       "      <td>@psirus2020 @zeroemissionnow @DEJH69619837 @Jo...</td>\n",
       "      <td>Houston, TX</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>[-95.446486  29.838495]</td>\n",
       "      <td>125</td>\n",
       "      <td>17</td>\n",
       "      <td>['saying', 'biden', 'known', 'racist', 'defend...</td>\n",
       "      <td>2</td>\n",
       "      <td>are you saying biden known racist while you  d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   date        user_name          user_loc  \\\n",
       "0   2020-10-10 11:41:36  susanha77835097      Florida, USA   \n",
       "3   2020-10-10 08:39:14      Parnell_100    United Kingdom   \n",
       "9   2020-10-10 05:19:12           cyn507  Philadelphia, PA   \n",
       "40  2020-10-10 01:22:40    KLehneiswxguy     United States   \n",
       "46  2020-10-10 00:29:13             Sp8d       Houston, TX   \n",
       "\n",
       "                                              message  \\\n",
       "0   @blossomingabyss @JoeBiden He filled his pocke...   \n",
       "3   @JoeBiden There is NO STOPPING this AMERICAN T...   \n",
       "9   Looks like @realDonaldTrump is running scared....   \n",
       "40  @NBSaphierMD @JoeBiden Because Joe Biden is ch...   \n",
       "46  @psirus2020 @zeroemissionnow @DEJH69619837 @Jo...   \n",
       "\n",
       "                    full_name         country country_code  \\\n",
       "0       Sunny Isles Beach, FL   United States           US   \n",
       "3   Belfast, Northern Ireland  United Kingdom           GB   \n",
       "9            Philadelphia, PA   United States           US   \n",
       "40            Beavercreek, OH   United States           US   \n",
       "46                Houston, TX   United States           US   \n",
       "\n",
       "                   geo_code  longitud_mensaje  palabras  \\\n",
       "0   [-80.125071  25.92906 ]               140        18   \n",
       "3     [-5.928413 54.595869]               140        23   \n",
       "9   [-75.117998  40.004866]               140        20   \n",
       "40  [-84.047553  39.727936]               139        20   \n",
       "46  [-95.446486  29.838495]               125        17   \n",
       "\n",
       "                                             refinado  predictions  \\\n",
       "0   ['filled', 'pocketskids', 'familyharris', 'unq...            2   \n",
       "3   ['stopping', 'american', 'trinity', 'train', '...            2   \n",
       "9   ['looks', 'like', 'running', 'scared', 'bag', ...            2   \n",
       "40  ['joe', 'biden', 'chickening', 'wanted', 'othe...            2   \n",
       "46  ['saying', 'biden', 'known', 'racist', 'defend...            2   \n",
       "\n",
       "                                     mensajeprocesado  \n",
       "0   filled his pocketskids familyharris unqualifie...  \n",
       "3   there stopping this american trinity train   b...  \n",
       "9   looks like running scared  his bag tricks does...  \n",
       "40  because joe biden chickening out  wanted other...  \n",
       "46  are you saying biden known racist while you  d...  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweet[df_tweet['predictions'] == 2].head(5) # negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_loc</th>\n",
       "      <th>message</th>\n",
       "      <th>full_name</th>\n",
       "      <th>country</th>\n",
       "      <th>country_code</th>\n",
       "      <th>geo_code</th>\n",
       "      <th>longitud_mensaje</th>\n",
       "      <th>palabras</th>\n",
       "      <th>refinado</th>\n",
       "      <th>predictions</th>\n",
       "      <th>mensajeprocesado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-10-10 11:19:05</td>\n",
       "      <td>tomborelli</td>\n",
       "      <td>Greenwich, CT</td>\n",
       "      <td>Supporting @JoeBiden means packing the Supreme...</td>\n",
       "      <td>Greenwich, CT</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>[-73.63941   41.050217]</td>\n",
       "      <td>144</td>\n",
       "      <td>17</td>\n",
       "      <td>['supporting', 'means', 'packing', 'supreme', ...</td>\n",
       "      <td>1</td>\n",
       "      <td>supporting means packing the supreme court lib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-10-10 09:39:10</td>\n",
       "      <td>John_Di_Lemme</td>\n",
       "      <td>(561) 847-3467</td>\n",
       "      <td>@ABC13News @realDonaldTrump @JoeBiden Nancy Pe...</td>\n",
       "      <td>West Palm Beach, FL</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>[-80.12262   26.721896]</td>\n",
       "      <td>133</td>\n",
       "      <td>15</td>\n",
       "      <td>['nancy', 'pelosi', 'nuts', 'joe', 'biden', 'k...</td>\n",
       "      <td>1</td>\n",
       "      <td>nancy pelosi nuts  joe biden and kamala harris...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-10-10 07:18:33</td>\n",
       "      <td>sqlblues</td>\n",
       "      <td>Weston-super-Mare, England</td>\n",
       "      <td>@FenrirWolf26 @Stanhope2011VJ Britons have als...</td>\n",
       "      <td>Weston-super-Mare, England</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>GB</td>\n",
       "      <td>[-2.94513  51.346796]</td>\n",
       "      <td>139</td>\n",
       "      <td>17</td>\n",
       "      <td>['britons', 'also', 'pumped', 'relentless', 'd...</td>\n",
       "      <td>1</td>\n",
       "      <td>britons have also been pumped relentless diet ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-10-10 06:56:05</td>\n",
       "      <td>_walkforACure</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>US presidential debate officially cancelled\\n\\...</td>\n",
       "      <td>East Midlands, England</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>GB</td>\n",
       "      <td>[-0.838055 52.796791]</td>\n",
       "      <td>87</td>\n",
       "      <td>9</td>\n",
       "      <td>['presidential', 'debate', 'officially', 'canc...</td>\n",
       "      <td>1</td>\n",
       "      <td>presidential debate officially cancelled sent ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-10-10 06:14:37</td>\n",
       "      <td>newollien</td>\n",
       "      <td>Wales</td>\n",
       "      <td>@blossomingabyss @JoeBiden Oh behave, you tit....</td>\n",
       "      <td>Bridgend, Wales</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>GB</td>\n",
       "      <td>[-3.58689  51.508115]</td>\n",
       "      <td>140</td>\n",
       "      <td>21</td>\n",
       "      <td>['behave', 'tit', 'trump', 'tactic', 'debate',...</td>\n",
       "      <td>1</td>\n",
       "      <td>behave  you tit  trump  only tactic the debate...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date      user_name                    user_loc  \\\n",
       "1  2020-10-10 11:19:05     tomborelli               Greenwich, CT   \n",
       "2  2020-10-10 09:39:10  John_Di_Lemme              (561) 847-3467   \n",
       "4  2020-10-10 07:18:33       sqlblues  Weston-super-Mare, England   \n",
       "5  2020-10-10 06:56:05  _walkforACure              United Kingdom   \n",
       "6  2020-10-10 06:14:37      newollien                      Wales    \n",
       "\n",
       "                                             message  \\\n",
       "1  Supporting @JoeBiden means packing the Supreme...   \n",
       "2  @ABC13News @realDonaldTrump @JoeBiden Nancy Pe...   \n",
       "4  @FenrirWolf26 @Stanhope2011VJ Britons have als...   \n",
       "5  US presidential debate officially cancelled\\n\\...   \n",
       "6  @blossomingabyss @JoeBiden Oh behave, you tit....   \n",
       "\n",
       "                    full_name         country country_code  \\\n",
       "1               Greenwich, CT   United States           US   \n",
       "2         West Palm Beach, FL   United States           US   \n",
       "4  Weston-super-Mare, England  United Kingdom           GB   \n",
       "5      East Midlands, England  United Kingdom           GB   \n",
       "6             Bridgend, Wales  United Kingdom           GB   \n",
       "\n",
       "                  geo_code  longitud_mensaje  palabras  \\\n",
       "1  [-73.63941   41.050217]               144        17   \n",
       "2  [-80.12262   26.721896]               133        15   \n",
       "4    [-2.94513  51.346796]               139        17   \n",
       "5    [-0.838055 52.796791]                87         9   \n",
       "6    [-3.58689  51.508115]               140        21   \n",
       "\n",
       "                                            refinado  predictions  \\\n",
       "1  ['supporting', 'means', 'packing', 'supreme', ...            1   \n",
       "2  ['nancy', 'pelosi', 'nuts', 'joe', 'biden', 'k...            1   \n",
       "4  ['britons', 'also', 'pumped', 'relentless', 'd...            1   \n",
       "5  ['presidential', 'debate', 'officially', 'canc...            1   \n",
       "6  ['behave', 'tit', 'trump', 'tactic', 'debate',...            1   \n",
       "\n",
       "                                    mensajeprocesado  \n",
       "1  supporting means packing the supreme court lib...  \n",
       "2  nancy pelosi nuts  joe biden and kamala harris...  \n",
       "4  britons have also been pumped relentless diet ...  \n",
       "5  presidential debate officially cancelled sent ...  \n",
       "6  behave  you tit  trump  only tactic the debate...  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweet[df_tweet['predictions'] == 1].head(5) # neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_loc</th>\n",
       "      <th>message</th>\n",
       "      <th>full_name</th>\n",
       "      <th>country</th>\n",
       "      <th>country_code</th>\n",
       "      <th>geo_code</th>\n",
       "      <th>longitud_mensaje</th>\n",
       "      <th>palabras</th>\n",
       "      <th>refinado</th>\n",
       "      <th>predictions</th>\n",
       "      <th>mensajeprocesado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2020-10-10 05:16:48</td>\n",
       "      <td>JoerGolfmiester</td>\n",
       "      <td>United States</td>\n",
       "      <td>@TheLeoTerrell @JoeBiden @SenKamalaHarris #Sle...</td>\n",
       "      <td>Florida, USA</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>[-83.804475  27.698682]</td>\n",
       "      <td>140</td>\n",
       "      <td>16</td>\n",
       "      <td>['sleepyjoebiden', 'remember', 'last', 'time',...</td>\n",
       "      <td>0</td>\n",
       "      <td>can  remember the last time wiped his butt  wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2020-10-10 05:10:22</td>\n",
       "      <td>colllleeen</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>I'll be honest... I don't understand the frami...</td>\n",
       "      <td>Abbotsford, British Columbia</td>\n",
       "      <td>Canada</td>\n",
       "      <td>CA</td>\n",
       "      <td>[-122.267074   49.086996]</td>\n",
       "      <td>140</td>\n",
       "      <td>21</td>\n",
       "      <td>['honest', 'understand', 'framing', 'vote', 'v...</td>\n",
       "      <td>0</td>\n",
       "      <td>honest    don  understand the framing   vote...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2020-10-10 04:30:52</td>\n",
       "      <td>Hutton8Eldon</td>\n",
       "      <td>canton Lake, Ok.</td>\n",
       "      <td>@swatkins109 @HeatherBarmore @Pangolin1214 @Jo...</td>\n",
       "      <td>Oklahoma, USA</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>[-98.716992  35.309046]</td>\n",
       "      <td>140</td>\n",
       "      <td>16</td>\n",
       "      <td>['joe', 'biden', 'care', 'americans', 'thing',...</td>\n",
       "      <td>0</td>\n",
       "      <td>joe biden don  care about any americans  only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2020-10-10 04:10:14</td>\n",
       "      <td>proudamericanmm</td>\n",
       "      <td>Philadelphia, PA</td>\n",
       "      <td>If you believe this, DM me about some swamp la...</td>\n",
       "      <td>Philadelphia, PA</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>[-75.117998  40.004866]</td>\n",
       "      <td>140</td>\n",
       "      <td>26</td>\n",
       "      <td>['believe', 'swamp', 'land', 'sale', 'jersey',...</td>\n",
       "      <td>0</td>\n",
       "      <td>you believe this  about some swamp land for sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2020-10-10 03:02:18</td>\n",
       "      <td>mega_tron801</td>\n",
       "      <td>O town, Utah</td>\n",
       "      <td>Listen, there is no definitive proof of Biden ...</td>\n",
       "      <td>Ogden, UT</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>[-111.96507    41.217798]</td>\n",
       "      <td>140</td>\n",
       "      <td>20</td>\n",
       "      <td>['listen', 'definitive', 'proof', 'biden', 'pe...</td>\n",
       "      <td>0</td>\n",
       "      <td>listen  there definitive proof biden being ped...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   date        user_name          user_loc  \\\n",
       "11  2020-10-10 05:16:48  JoerGolfmiester     United States   \n",
       "13  2020-10-10 05:10:22       colllleeen  British Columbia   \n",
       "17  2020-10-10 04:30:52     Hutton8Eldon  canton Lake, Ok.   \n",
       "20  2020-10-10 04:10:14  proudamericanmm  Philadelphia, PA   \n",
       "25  2020-10-10 03:02:18     mega_tron801     O town, Utah    \n",
       "\n",
       "                                              message  \\\n",
       "11  @TheLeoTerrell @JoeBiden @SenKamalaHarris #Sle...   \n",
       "13  I'll be honest... I don't understand the frami...   \n",
       "17  @swatkins109 @HeatherBarmore @Pangolin1214 @Jo...   \n",
       "20  If you believe this, DM me about some swamp la...   \n",
       "25  Listen, there is no definitive proof of Biden ...   \n",
       "\n",
       "                       full_name        country country_code  \\\n",
       "11                  Florida, USA  United States           US   \n",
       "13  Abbotsford, British Columbia         Canada           CA   \n",
       "17                 Oklahoma, USA  United States           US   \n",
       "20              Philadelphia, PA  United States           US   \n",
       "25                     Ogden, UT  United States           US   \n",
       "\n",
       "                     geo_code  longitud_mensaje  palabras  \\\n",
       "11    [-83.804475  27.698682]               140        16   \n",
       "13  [-122.267074   49.086996]               140        21   \n",
       "17    [-98.716992  35.309046]               140        16   \n",
       "20    [-75.117998  40.004866]               140        26   \n",
       "25  [-111.96507    41.217798]               140        20   \n",
       "\n",
       "                                             refinado  predictions  \\\n",
       "11  ['sleepyjoebiden', 'remember', 'last', 'time',...            0   \n",
       "13  ['honest', 'understand', 'framing', 'vote', 'v...            0   \n",
       "17  ['joe', 'biden', 'care', 'americans', 'thing',...            0   \n",
       "20  ['believe', 'swamp', 'land', 'sale', 'jersey',...            0   \n",
       "25  ['listen', 'definitive', 'proof', 'biden', 'pe...            0   \n",
       "\n",
       "                                     mensajeprocesado  \n",
       "11  can  remember the last time wiped his butt  wo...  \n",
       "13    honest    don  understand the framing   vote...  \n",
       "17  joe biden don  care about any americans  only ...  \n",
       "20  you believe this  about some swamp land for sa...  \n",
       "25  listen  there definitive proof biden being ped...  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweet[df_tweet['predictions'] == 0].head(5) # negativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of positve tagged sentences is:  498\n",
      "number of neutral tagged sentences is: 1714\n",
      "number of negative tagged sentences is: 292\n",
      "total length of the data is:            2504\n"
     ]
    }
   ],
   "source": [
    "positives = df_tweet['predictions'][df_tweet.predictions == 2]\n",
    "neutral = df_tweet['predictions'][df_tweet.predictions == 1]\n",
    "negatives = df_tweet['predictions'][df_tweet.predictions == 0]\n",
    "\n",
    "print('number of positve tagged sentences is:  {}'.format(len(positives)))\n",
    "print('number of neutral tagged sentences is: {}'.format(len(neutral)))\n",
    "print('number of negative tagged sentences is: {}'.format(len(negatives)))\n",
    "print('total length of the data is:            {}'.format(df_tweet.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet.to_csv('./Outputs/df_tweets_pred.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
