{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly\n",
    "from collections import Counter\n",
    "import re\n",
    "import string \n",
    "\n",
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.porter import * \n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= pd.read_csv(\"./Outputs/FilteredDataSet.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['date',\n",
       " 'user_name',\n",
       " 'user_loc',\n",
       " 'message',\n",
       " 'full_name',\n",
       " 'country',\n",
       " 'country_code',\n",
       " 'geo_code',\n",
       " 'longitud_mensaje',\n",
       " 'palabras',\n",
       " 'refinado']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_loc</th>\n",
       "      <th>message</th>\n",
       "      <th>full_name</th>\n",
       "      <th>country</th>\n",
       "      <th>country_code</th>\n",
       "      <th>geo_code</th>\n",
       "      <th>longitud_mensaje</th>\n",
       "      <th>palabras</th>\n",
       "      <th>refinado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-10-10 11:41:36</td>\n",
       "      <td>susanha77835097</td>\n",
       "      <td>Florida, USA</td>\n",
       "      <td>@blossomingabyss @JoeBiden He filled his pocke...</td>\n",
       "      <td>Sunny Isles Beach, FL</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>[-80.125071  25.92906 ]</td>\n",
       "      <td>140</td>\n",
       "      <td>18</td>\n",
       "      <td>['filled', 'pocketskids', 'familyharris', 'unq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-10-10 11:19:05</td>\n",
       "      <td>tomborelli</td>\n",
       "      <td>Greenwich, CT</td>\n",
       "      <td>Supporting @JoeBiden means packing the Supreme...</td>\n",
       "      <td>Greenwich, CT</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>[-73.63941   41.050217]</td>\n",
       "      <td>144</td>\n",
       "      <td>17</td>\n",
       "      <td>['supporting', 'means', 'packing', 'supreme', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-10-10 09:39:10</td>\n",
       "      <td>John_Di_Lemme</td>\n",
       "      <td>(561) 847-3467</td>\n",
       "      <td>@ABC13News @realDonaldTrump @JoeBiden Nancy Pe...</td>\n",
       "      <td>West Palm Beach, FL</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>[-80.12262   26.721896]</td>\n",
       "      <td>133</td>\n",
       "      <td>15</td>\n",
       "      <td>['nancy', 'pelosi', 'nuts', 'joe', 'biden', 'k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-10-10 08:39:14</td>\n",
       "      <td>Parnell_100</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>@JoeBiden There is NO STOPPING this AMERICAN T...</td>\n",
       "      <td>Belfast, Northern Ireland</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>GB</td>\n",
       "      <td>[-5.928413 54.595869]</td>\n",
       "      <td>140</td>\n",
       "      <td>23</td>\n",
       "      <td>['stopping', 'american', 'trinity', 'train', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-10-10 07:18:33</td>\n",
       "      <td>sqlblues</td>\n",
       "      <td>Weston-super-Mare, England</td>\n",
       "      <td>@FenrirWolf26 @Stanhope2011VJ Britons have als...</td>\n",
       "      <td>Weston-super-Mare, England</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>GB</td>\n",
       "      <td>[-2.94513  51.346796]</td>\n",
       "      <td>139</td>\n",
       "      <td>17</td>\n",
       "      <td>['britons', 'also', 'pumped', 'relentless', 'd...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date        user_name                    user_loc  \\\n",
       "0  2020-10-10 11:41:36  susanha77835097                Florida, USA   \n",
       "1  2020-10-10 11:19:05       tomborelli               Greenwich, CT   \n",
       "2  2020-10-10 09:39:10    John_Di_Lemme              (561) 847-3467   \n",
       "3  2020-10-10 08:39:14      Parnell_100              United Kingdom   \n",
       "4  2020-10-10 07:18:33         sqlblues  Weston-super-Mare, England   \n",
       "\n",
       "                                             message  \\\n",
       "0  @blossomingabyss @JoeBiden He filled his pocke...   \n",
       "1  Supporting @JoeBiden means packing the Supreme...   \n",
       "2  @ABC13News @realDonaldTrump @JoeBiden Nancy Pe...   \n",
       "3  @JoeBiden There is NO STOPPING this AMERICAN T...   \n",
       "4  @FenrirWolf26 @Stanhope2011VJ Britons have als...   \n",
       "\n",
       "                    full_name         country country_code  \\\n",
       "0       Sunny Isles Beach, FL   United States           US   \n",
       "1               Greenwich, CT   United States           US   \n",
       "2         West Palm Beach, FL   United States           US   \n",
       "3   Belfast, Northern Ireland  United Kingdom           GB   \n",
       "4  Weston-super-Mare, England  United Kingdom           GB   \n",
       "\n",
       "                  geo_code  longitud_mensaje  palabras  \\\n",
       "0  [-80.125071  25.92906 ]               140        18   \n",
       "1  [-73.63941   41.050217]               144        17   \n",
       "2  [-80.12262   26.721896]               133        15   \n",
       "3    [-5.928413 54.595869]               140        23   \n",
       "4    [-2.94513  51.346796]               139        17   \n",
       "\n",
       "                                            refinado  \n",
       "0  ['filled', 'pocketskids', 'familyharris', 'unq...  \n",
       "1  ['supporting', 'means', 'packing', 'supreme', ...  \n",
       "2  ['nancy', 'pelosi', 'nuts', 'joe', 'biden', 'k...  \n",
       "3  ['stopping', 'american', 'trinity', 'train', '...  \n",
       "4  ['britons', 'also', 'pumped', 'relentless', 'd...  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet= test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = df_tweet['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/danielgarcia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def processTweet(tweet):\n",
    "    \"\"\"\n",
    "    Takes in a string of text, then performs the following:\n",
    "    1. Removes links, special characters and other bulk cleaning\n",
    "    2. Returns a list of the tidy text\n",
    "    \"\"\"\n",
    "    # Remove HTML special entities (e.g. &amp;)\n",
    "    tweet = re.sub(r'\\&\\w*;', '', tweet)\n",
    "    #Convert @username to AT_USER\n",
    "    tweet = re.sub('@[^\\s]+','',tweet)\n",
    "    # Remove tickers\n",
    "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
    "    # To lowercase\n",
    "    tweet = tweet.lower()\n",
    "    # Remove hyperlinks\n",
    "    tweet = re.sub(r'https?:\\/\\/.*\\/\\w*', '', tweet)\n",
    "    # Remove hashtags\n",
    "    tweet = re.sub(r'#\\w*', '', tweet)\n",
    "    # Remove words with 2 or fewer letters\n",
    "    tweet = re.sub(r'\\b\\w{1,2}\\b', '', tweet)\n",
    "    # Remove whitespace (including new line characters)\n",
    "    tweet = re.sub(r'\\s\\s+', ' ', tweet)\n",
    "    # Remove single space remaining at the front of the tweet.\n",
    "    tweet = tweet.lstrip(' ') \n",
    "    # Remove characters beyond Basic Multilingual Plane (BMP) of Unicode:\n",
    "    tweet = ''.join(c for c in tweet if c <= '\\uFFFF') \n",
    "    return tweet\n",
    "# tokenize helper function\n",
    "def text_process(tweet):\n",
    "    \"\"\"\n",
    "    Takes in a string of text, then performs the following:\n",
    "    1. Remove all punctuation\n",
    "    2. Remove all stopwords\n",
    "    3. Returns a list of the cleaned text\n",
    "    \"\"\"\n",
    "    # Check characters to see if they are in punctuation\n",
    "    nopunc = [char for char in list(tweet) if char not in string.punctuation]\n",
    "\n",
    "    # Join the characters again to form the string.\n",
    "    nopunc = ''.join(nopunc)\n",
    "    \n",
    "    # Now just remove any stopwords\n",
    "    return [word for word in nopunc.lower().split() if word.lower() not in stopwords.words('english')]\n",
    "\n",
    "# Lexicon normalisation with Stemming \n",
    "def stemming(tokens):\n",
    "  \"\"\"\n",
    "  Takes in a string of text, then performs the following:\n",
    "  1. Replace words for its root based on orter Stemmer rule.\n",
    "  2. Returns normalised text\n",
    "   \"\"\"\n",
    "  stemmer = PorterStemmer()\n",
    "  x = [stemmer.stem(w) for w in tokens]\n",
    "   \n",
    "  return ' '.join(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    filled his pocketskids familyharris unqualifie...\n",
      "1    supporting means packing the supreme court lib...\n",
      "2    nancy pelosi nuts! joe biden and kamala harris...\n",
      "3    there stopping this american trinity train - b...\n",
      "4    britons have also been pumped relentless diet ...\n",
      "Name: mensajeprocesado, dtype: object\n",
      "0    filled his pocketskids familyharris unqualifie...\n",
      "1    supporting means packing the supreme court lib...\n",
      "2    nancy pelosi nuts  joe biden and kamala harris...\n",
      "3    there stopping this american trinity train   b...\n",
      "4    britons have also been pumped relentless diet ...\n",
      "Name: mensajeprocesado, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing\n",
    "df_tweet['mensajeprocesado'] = df_tweet['message'].apply(processTweet)\n",
    "print(df_tweet.mensajeprocesado.head())\n",
    "# Double check\n",
    "df_tweet['mensajeprocesado'] = df_tweet['mensajeprocesado'].str.replace(\"[^a-zA-Z#]\", \" \") \n",
    "print(df_tweet.mensajeprocesado.head())\n",
    "# tokenize tidy_tweet column and create a column for tokens\n",
    "test['tokens'] = df_tweet['refinado'].copy() # tokenize\n",
    "\n",
    "# Normalisation\n",
    "stemmer = PorterStemmer() \n",
    "normalized_tweet = df_tweet['mensajeprocesado'].apply(lambda x: [stemmer.stem(i) for i in x]) # stemming\n",
    "\n",
    "for i in range(len(normalized_tweet)):\n",
    "    normalized_tweet[i] = ''.join(normalized_tweet[i])    \n",
    "df_tweet['mensajeprocesado'] = normalized_tweet\n",
    "\n",
    "df_tweet.drop(df_tweet.filter(regex=\"Unname\"),axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = df_tweet['message'].apply(processTweet)\n",
    "nb_words = 10000  \n",
    "tk = Tokenizer(num_words=nb_words) #tokenize\n",
    "tk.fit_on_texts(tweet) #tokenize\n",
    "\n",
    "# format your input for the neural net\n",
    "tweets_seq = tk.texts_to_sequences(tweet) # integer encode\n",
    "tweet_array = pad_sequences(tweets_seq, # good to use length it was trained on\n",
    "                            maxlen=39) # Convert to 2-D Numpy array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"modeloKerasreg\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 28, 128)           1280000   \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 28, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 200)               263200    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 603       \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 1,543,803\n",
      "Trainable params: 1,543,803\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "LSTM_model = load_model('./models/LSTM_model.h5')\n",
    "LSTM_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 28) for input Tensor(\"embedding_3_input_5:0\", shape=(None, 28), dtype=float32), but it was called on an input with incompatible shape (2504, 39).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2504, 13)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = len(tweet_array)\n",
    "\n",
    "# for human-friendly printing\n",
    "labels = ['negative', 'positive']\n",
    "\n",
    "# Predict and get output from the model\n",
    "pred= LSTM_model.predict_classes(tweet_array, batch_size)\n",
    "\n",
    "# append predictions to dataframe\n",
    "df_tweet['predictions'] = pred\n",
    "df_tweet.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_loc</th>\n",
       "      <th>message</th>\n",
       "      <th>full_name</th>\n",
       "      <th>country</th>\n",
       "      <th>country_code</th>\n",
       "      <th>geo_code</th>\n",
       "      <th>longitud_mensaje</th>\n",
       "      <th>palabras</th>\n",
       "      <th>refinado</th>\n",
       "      <th>predictions</th>\n",
       "      <th>mensajeprocesado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-10-10 11:41:36</td>\n",
       "      <td>susanha77835097</td>\n",
       "      <td>Florida, USA</td>\n",
       "      <td>@blossomingabyss @JoeBiden He filled his pocke...</td>\n",
       "      <td>Sunny Isles Beach, FL</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>[-80.125071  25.92906 ]</td>\n",
       "      <td>140</td>\n",
       "      <td>18</td>\n",
       "      <td>['filled', 'pocketskids', 'familyharris', 'unq...</td>\n",
       "      <td>2</td>\n",
       "      <td>filled his pocketskids familyharris unqualifie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-10-10 08:39:14</td>\n",
       "      <td>Parnell_100</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>@JoeBiden There is NO STOPPING this AMERICAN T...</td>\n",
       "      <td>Belfast, Northern Ireland</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>GB</td>\n",
       "      <td>[-5.928413 54.595869]</td>\n",
       "      <td>140</td>\n",
       "      <td>23</td>\n",
       "      <td>['stopping', 'american', 'trinity', 'train', '...</td>\n",
       "      <td>2</td>\n",
       "      <td>there stopping this american trinity train   b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-10-10 05:19:12</td>\n",
       "      <td>cyn507</td>\n",
       "      <td>Philadelphia, PA</td>\n",
       "      <td>Looks like @realDonaldTrump is running scared....</td>\n",
       "      <td>Philadelphia, PA</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>[-75.117998  40.004866]</td>\n",
       "      <td>140</td>\n",
       "      <td>20</td>\n",
       "      <td>['looks', 'like', 'running', 'scared', 'bag', ...</td>\n",
       "      <td>2</td>\n",
       "      <td>looks like running scared  his bag tricks does...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2020-10-10 01:22:40</td>\n",
       "      <td>KLehneiswxguy</td>\n",
       "      <td>United States</td>\n",
       "      <td>@NBSaphierMD @JoeBiden Because Joe Biden is ch...</td>\n",
       "      <td>Beavercreek, OH</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>[-84.047553  39.727936]</td>\n",
       "      <td>139</td>\n",
       "      <td>20</td>\n",
       "      <td>['joe', 'biden', 'chickening', 'wanted', 'othe...</td>\n",
       "      <td>2</td>\n",
       "      <td>because joe biden chickening out  wanted other...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2020-10-10 00:29:13</td>\n",
       "      <td>Sp8d</td>\n",
       "      <td>Houston, TX</td>\n",
       "      <td>@psirus2020 @zeroemissionnow @DEJH69619837 @Jo...</td>\n",
       "      <td>Houston, TX</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>[-95.446486  29.838495]</td>\n",
       "      <td>125</td>\n",
       "      <td>17</td>\n",
       "      <td>['saying', 'biden', 'known', 'racist', 'defend...</td>\n",
       "      <td>2</td>\n",
       "      <td>are you saying biden known racist while you  d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   date        user_name          user_loc  \\\n",
       "0   2020-10-10 11:41:36  susanha77835097      Florida, USA   \n",
       "3   2020-10-10 08:39:14      Parnell_100    United Kingdom   \n",
       "9   2020-10-10 05:19:12           cyn507  Philadelphia, PA   \n",
       "40  2020-10-10 01:22:40    KLehneiswxguy     United States   \n",
       "46  2020-10-10 00:29:13             Sp8d       Houston, TX   \n",
       "\n",
       "                                              message  \\\n",
       "0   @blossomingabyss @JoeBiden He filled his pocke...   \n",
       "3   @JoeBiden There is NO STOPPING this AMERICAN T...   \n",
       "9   Looks like @realDonaldTrump is running scared....   \n",
       "40  @NBSaphierMD @JoeBiden Because Joe Biden is ch...   \n",
       "46  @psirus2020 @zeroemissionnow @DEJH69619837 @Jo...   \n",
       "\n",
       "                    full_name         country country_code  \\\n",
       "0       Sunny Isles Beach, FL   United States           US   \n",
       "3   Belfast, Northern Ireland  United Kingdom           GB   \n",
       "9            Philadelphia, PA   United States           US   \n",
       "40            Beavercreek, OH   United States           US   \n",
       "46                Houston, TX   United States           US   \n",
       "\n",
       "                   geo_code  longitud_mensaje  palabras  \\\n",
       "0   [-80.125071  25.92906 ]               140        18   \n",
       "3     [-5.928413 54.595869]               140        23   \n",
       "9   [-75.117998  40.004866]               140        20   \n",
       "40  [-84.047553  39.727936]               139        20   \n",
       "46  [-95.446486  29.838495]               125        17   \n",
       "\n",
       "                                             refinado  predictions  \\\n",
       "0   ['filled', 'pocketskids', 'familyharris', 'unq...            2   \n",
       "3   ['stopping', 'american', 'trinity', 'train', '...            2   \n",
       "9   ['looks', 'like', 'running', 'scared', 'bag', ...            2   \n",
       "40  ['joe', 'biden', 'chickening', 'wanted', 'othe...            2   \n",
       "46  ['saying', 'biden', 'known', 'racist', 'defend...            2   \n",
       "\n",
       "                                     mensajeprocesado  \n",
       "0   filled his pocketskids familyharris unqualifie...  \n",
       "3   there stopping this american trinity train   b...  \n",
       "9   looks like running scared  his bag tricks does...  \n",
       "40  because joe biden chickening out  wanted other...  \n",
       "46  are you saying biden known racist while you  d...  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweet[df_tweet['predictions'] == 2].head(5) # negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of positve tagged sentences is:  498\n",
      "number of neutral tagged sentences is: 1714\n",
      "number of negative tagged sentences is: 292\n",
      "total length of the data is:            2504\n"
     ]
    }
   ],
   "source": [
    "positives = df_tweet['predictions'][df_tweet.predictions == 2]\n",
    "neutral = df_tweet['predictions'][df_tweet.predictions == 1]\n",
    "negatives = df_tweet['predictions'][df_tweet.predictions == 0]\n",
    "\n",
    "print('number of positve tagged sentences is:  {}'.format(len(positives)))\n",
    "print('number of neutral tagged sentences is: {}'.format(len(neutral)))\n",
    "print('number of negative tagged sentences is: {}'.format(len(negatives)))\n",
    "print('total length of the data is:            {}'.format(df_tweet.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
