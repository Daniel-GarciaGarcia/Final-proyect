{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "import time\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, HashingVectorizer, CountVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.svm import LinearSVC\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_loc</th>\n",
       "      <th>message</th>\n",
       "      <th>full_name</th>\n",
       "      <th>country</th>\n",
       "      <th>country_code</th>\n",
       "      <th>geo_code</th>\n",
       "      <th>longitud_mensaje</th>\n",
       "      <th>palabras</th>\n",
       "      <th>refinado</th>\n",
       "      <th>latitud</th>\n",
       "      <th>longitud</th>\n",
       "      <th>states</th>\n",
       "      <th>Polaridad</th>\n",
       "      <th>Subjetividad</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-10-10 11:41:36</td>\n",
       "      <td>susanha77835097</td>\n",
       "      <td>Florida, USA</td>\n",
       "      <td>@blossomingabyss @JoeBiden He filled his pocke...</td>\n",
       "      <td>Sunny Isles Beach, FL</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>[-80.125071  25.92906 ]</td>\n",
       "      <td>140</td>\n",
       "      <td>18</td>\n",
       "      <td>['filled', 'pocketskids', 'familyharris', 'unq...</td>\n",
       "      <td>-80.125071</td>\n",
       "      <td>25.929060</td>\n",
       "      <td>FL</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.90</td>\n",
       "      <td>Positiva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-10-10 11:19:05</td>\n",
       "      <td>tomborelli</td>\n",
       "      <td>Greenwich, CT</td>\n",
       "      <td>Supporting @JoeBiden means packing the Supreme...</td>\n",
       "      <td>Greenwich, CT</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>[-73.63941   41.050217]</td>\n",
       "      <td>144</td>\n",
       "      <td>17</td>\n",
       "      <td>['supporting', 'means', 'packing', 'supreme', ...</td>\n",
       "      <td>-73.639410</td>\n",
       "      <td>41.050217</td>\n",
       "      <td>CT</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>Positiva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-10-10 09:39:10</td>\n",
       "      <td>John_Di_Lemme</td>\n",
       "      <td>(561) 847-3467</td>\n",
       "      <td>@ABC13News @realDonaldTrump @JoeBiden Nancy Pe...</td>\n",
       "      <td>West Palm Beach, FL</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>[-80.12262   26.721896]</td>\n",
       "      <td>133</td>\n",
       "      <td>15</td>\n",
       "      <td>['nancy', 'pelosi', 'nuts', 'joe', 'biden', 'k...</td>\n",
       "      <td>-80.122620</td>\n",
       "      <td>26.721896</td>\n",
       "      <td>FL</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-10-10 08:39:14</td>\n",
       "      <td>Parnell_100</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>@JoeBiden There is NO STOPPING this AMERICAN T...</td>\n",
       "      <td>Belfast, Northern Ireland</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>GB</td>\n",
       "      <td>[-5.928413 54.595869]</td>\n",
       "      <td>140</td>\n",
       "      <td>23</td>\n",
       "      <td>['stopping', 'american', 'trinity', 'train', '...</td>\n",
       "      <td>-5.928413</td>\n",
       "      <td>54.595869</td>\n",
       "      <td>Non_USA</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-10-10 07:18:33</td>\n",
       "      <td>sqlblues</td>\n",
       "      <td>Weston-super-Mare, England</td>\n",
       "      <td>@FenrirWolf26 @Stanhope2011VJ Britons have als...</td>\n",
       "      <td>Weston-super-Mare, England</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>GB</td>\n",
       "      <td>[-2.94513  51.346796]</td>\n",
       "      <td>139</td>\n",
       "      <td>17</td>\n",
       "      <td>['britons', 'also', 'pumped', 'relentless', 'd...</td>\n",
       "      <td>-2.945130</td>\n",
       "      <td>51.346796</td>\n",
       "      <td>Non_USA</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>0.40</td>\n",
       "      <td>Negativa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date        user_name                    user_loc  \\\n",
       "0  2020-10-10 11:41:36  susanha77835097                Florida, USA   \n",
       "1  2020-10-10 11:19:05       tomborelli               Greenwich, CT   \n",
       "2  2020-10-10 09:39:10    John_Di_Lemme              (561) 847-3467   \n",
       "3  2020-10-10 08:39:14      Parnell_100              United Kingdom   \n",
       "4  2020-10-10 07:18:33         sqlblues  Weston-super-Mare, England   \n",
       "\n",
       "                                             message  \\\n",
       "0  @blossomingabyss @JoeBiden He filled his pocke...   \n",
       "1  Supporting @JoeBiden means packing the Supreme...   \n",
       "2  @ABC13News @realDonaldTrump @JoeBiden Nancy Pe...   \n",
       "3  @JoeBiden There is NO STOPPING this AMERICAN T...   \n",
       "4  @FenrirWolf26 @Stanhope2011VJ Britons have als...   \n",
       "\n",
       "                    full_name         country country_code  \\\n",
       "0       Sunny Isles Beach, FL   United States           US   \n",
       "1               Greenwich, CT   United States           US   \n",
       "2         West Palm Beach, FL   United States           US   \n",
       "3   Belfast, Northern Ireland  United Kingdom           GB   \n",
       "4  Weston-super-Mare, England  United Kingdom           GB   \n",
       "\n",
       "                  geo_code  longitud_mensaje  palabras  \\\n",
       "0  [-80.125071  25.92906 ]               140        18   \n",
       "1  [-73.63941   41.050217]               144        17   \n",
       "2  [-80.12262   26.721896]               133        15   \n",
       "3    [-5.928413 54.595869]               140        23   \n",
       "4    [-2.94513  51.346796]               139        17   \n",
       "\n",
       "                                            refinado    latitud   longitud  \\\n",
       "0  ['filled', 'pocketskids', 'familyharris', 'unq... -80.125071  25.929060   \n",
       "1  ['supporting', 'means', 'packing', 'supreme', ... -73.639410  41.050217   \n",
       "2  ['nancy', 'pelosi', 'nuts', 'joe', 'biden', 'k... -80.122620  26.721896   \n",
       "3  ['stopping', 'american', 'trinity', 'train', '...  -5.928413  54.595869   \n",
       "4  ['britons', 'also', 'pumped', 'relentless', 'd...  -2.945130  51.346796   \n",
       "\n",
       "    states  Polaridad  Subjetividad     Label  \n",
       "0       FL       0.40          0.90  Positiva  \n",
       "1       CT       0.25          0.25  Positiva  \n",
       "2       FL       0.00          0.00   Neutral  \n",
       "3  Non_USA       0.00          0.00   Neutral  \n",
       "4  Non_USA      -0.30          0.40  Negativa  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent= pd.read_csv(\"./Outputs/sentimentos_tweeteros.csv\")\n",
    "sent.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label_enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label_enc\n",
       "0          2\n",
       "1          2\n",
       "2          1\n",
       "3          1\n",
       "4          0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "sent[\"Label_enc\"] = le.fit_transform(sent[\"Label\"])\n",
    "\n",
    "# Display the encoded labels\n",
    "display(sent[[\"Label_enc\"]].head())\n",
    "\n",
    "# Select the features and the target\n",
    "X = sent['refinado']\n",
    "y = sent[\"Label_enc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.52\n"
     ]
    }
   ],
   "source": [
    "tfidfstops=stopwords.words('english')\n",
    "vectorizer = TfidfVectorizer(max_features=5000, stop_words= tfidfstops)\n",
    "\n",
    "# Create the tf-idf vectorizer\n",
    "model_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# First fit the vectorizer with our training set\n",
    "tfidf_train = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Now we can fit our test data with the same vectorizer\n",
    "tfidf_test = vectorizer.transform(X_test)\n",
    "\n",
    "# Initialize the Bernoulli Naive Bayes classifier\n",
    "nb = BernoulliNB()\n",
    "\n",
    "# Fit the model\n",
    "nb.fit(tfidf_train, y_train)\n",
    "\n",
    "# Print the accuracy score\n",
    "best_accuracy = cross_val_score(nb, tfidf_test, y_test, cv=10, scoring='accuracy').max()\n",
    "print(\"Accuracy:\",best_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision del 52%, un poco mejor que lanzar una moneda al aire y elegir un resultado. \n",
    "# HAY QUE MEJORARLO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "Matriz 3x3 donde se ven los tweets que se catalogaron erroneamente\n",
      "\n",
      "[[ 29  66  17]\n",
      " [  0 225   7]\n",
      " [  1  59  97]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.26      0.41       112\n",
      "           1       0.64      0.97      0.77       232\n",
      "           2       0.80      0.62      0.70       157\n",
      "\n",
      "    accuracy                           0.70       501\n",
      "   macro avg       0.80      0.62      0.63       501\n",
      "weighted avg       0.77      0.70      0.67       501\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = nb.predict(tfidf_test)\n",
    "\n",
    "# Print the Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix\\nMatriz 3x3 donde se ven los tweets que se catalogaron erroneamente\\n\")\n",
    "print(cm)\n",
    "\n",
    "# Print the Classification Report\n",
    "cr = classification_report(y_test, y_pred)\n",
    "print(\"\\n\\nClassification Report\\n\")\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(nb, open(\"./Outputs/model.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_loc</th>\n",
       "      <th>message</th>\n",
       "      <th>full_name</th>\n",
       "      <th>country</th>\n",
       "      <th>country_code</th>\n",
       "      <th>geo_code</th>\n",
       "      <th>longitud_mensaje</th>\n",
       "      <th>palabras</th>\n",
       "      <th>refinado</th>\n",
       "      <th>latitud</th>\n",
       "      <th>longitud</th>\n",
       "      <th>states</th>\n",
       "      <th>Polaridad</th>\n",
       "      <th>Subjetividad</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-10-10 11:41:36</td>\n",
       "      <td>susanha77835097</td>\n",
       "      <td>Florida, USA</td>\n",
       "      <td>@blossomingabyss @JoeBiden He filled his pocke...</td>\n",
       "      <td>Sunny Isles Beach, FL</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>[-80.125071  25.92906 ]</td>\n",
       "      <td>140</td>\n",
       "      <td>18</td>\n",
       "      <td>['filled', 'pocketskids', 'familyharris', 'unq...</td>\n",
       "      <td>-80.125071</td>\n",
       "      <td>25.929060</td>\n",
       "      <td>FL</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.90</td>\n",
       "      <td>Positiva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-10-10 11:19:05</td>\n",
       "      <td>tomborelli</td>\n",
       "      <td>Greenwich, CT</td>\n",
       "      <td>Supporting @JoeBiden means packing the Supreme...</td>\n",
       "      <td>Greenwich, CT</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>[-73.63941   41.050217]</td>\n",
       "      <td>144</td>\n",
       "      <td>17</td>\n",
       "      <td>['supporting', 'means', 'packing', 'supreme', ...</td>\n",
       "      <td>-73.639410</td>\n",
       "      <td>41.050217</td>\n",
       "      <td>CT</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>Positiva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-10-10 09:39:10</td>\n",
       "      <td>John_Di_Lemme</td>\n",
       "      <td>(561) 847-3467</td>\n",
       "      <td>@ABC13News @realDonaldTrump @JoeBiden Nancy Pe...</td>\n",
       "      <td>West Palm Beach, FL</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>[-80.12262   26.721896]</td>\n",
       "      <td>133</td>\n",
       "      <td>15</td>\n",
       "      <td>['nancy', 'pelosi', 'nuts', 'joe', 'biden', 'k...</td>\n",
       "      <td>-80.122620</td>\n",
       "      <td>26.721896</td>\n",
       "      <td>FL</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-10-10 08:39:14</td>\n",
       "      <td>Parnell_100</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>@JoeBiden There is NO STOPPING this AMERICAN T...</td>\n",
       "      <td>Belfast, Northern Ireland</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>GB</td>\n",
       "      <td>[-5.928413 54.595869]</td>\n",
       "      <td>140</td>\n",
       "      <td>23</td>\n",
       "      <td>['stopping', 'american', 'trinity', 'train', '...</td>\n",
       "      <td>-5.928413</td>\n",
       "      <td>54.595869</td>\n",
       "      <td>Non_USA</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-10-10 07:18:33</td>\n",
       "      <td>sqlblues</td>\n",
       "      <td>Weston-super-Mare, England</td>\n",
       "      <td>@FenrirWolf26 @Stanhope2011VJ Britons have als...</td>\n",
       "      <td>Weston-super-Mare, England</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>GB</td>\n",
       "      <td>[-2.94513  51.346796]</td>\n",
       "      <td>139</td>\n",
       "      <td>17</td>\n",
       "      <td>['britons', 'also', 'pumped', 'relentless', 'd...</td>\n",
       "      <td>-2.945130</td>\n",
       "      <td>51.346796</td>\n",
       "      <td>Non_USA</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>0.40</td>\n",
       "      <td>Negativa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date        user_name                    user_loc  \\\n",
       "0  2020-10-10 11:41:36  susanha77835097                Florida, USA   \n",
       "1  2020-10-10 11:19:05       tomborelli               Greenwich, CT   \n",
       "2  2020-10-10 09:39:10    John_Di_Lemme              (561) 847-3467   \n",
       "3  2020-10-10 08:39:14      Parnell_100              United Kingdom   \n",
       "4  2020-10-10 07:18:33         sqlblues  Weston-super-Mare, England   \n",
       "\n",
       "                                             message  \\\n",
       "0  @blossomingabyss @JoeBiden He filled his pocke...   \n",
       "1  Supporting @JoeBiden means packing the Supreme...   \n",
       "2  @ABC13News @realDonaldTrump @JoeBiden Nancy Pe...   \n",
       "3  @JoeBiden There is NO STOPPING this AMERICAN T...   \n",
       "4  @FenrirWolf26 @Stanhope2011VJ Britons have als...   \n",
       "\n",
       "                    full_name         country country_code  \\\n",
       "0       Sunny Isles Beach, FL   United States           US   \n",
       "1               Greenwich, CT   United States           US   \n",
       "2         West Palm Beach, FL   United States           US   \n",
       "3   Belfast, Northern Ireland  United Kingdom           GB   \n",
       "4  Weston-super-Mare, England  United Kingdom           GB   \n",
       "\n",
       "                  geo_code  longitud_mensaje  palabras  \\\n",
       "0  [-80.125071  25.92906 ]               140        18   \n",
       "1  [-73.63941   41.050217]               144        17   \n",
       "2  [-80.12262   26.721896]               133        15   \n",
       "3    [-5.928413 54.595869]               140        23   \n",
       "4    [-2.94513  51.346796]               139        17   \n",
       "\n",
       "                                            refinado    latitud   longitud  \\\n",
       "0  ['filled', 'pocketskids', 'familyharris', 'unq... -80.125071  25.929060   \n",
       "1  ['supporting', 'means', 'packing', 'supreme', ... -73.639410  41.050217   \n",
       "2  ['nancy', 'pelosi', 'nuts', 'joe', 'biden', 'k... -80.122620  26.721896   \n",
       "3  ['stopping', 'american', 'trinity', 'train', '...  -5.928413  54.595869   \n",
       "4  ['britons', 'also', 'pumped', 'relentless', 'd...  -2.945130  51.346796   \n",
       "\n",
       "    states  Polaridad  Subjetividad     Label  \n",
       "0       FL       0.40          0.90  Positiva  \n",
       "1       CT       0.25          0.25  Positiva  \n",
       "2       FL       0.00          0.00   Neutral  \n",
       "3  Non_USA       0.00          0.00   Neutral  \n",
       "4  Non_USA      -0.30          0.40  Negativa  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=pd.read_csv(\"./Outputs/sentimentos_tweeteros.csv\")\n",
    "train.head()\n",
    "test=pd.read_csv(\"./Outputs/sentimentos_tweeteros.csv\")\n",
    "train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerar_polaridad(polaridad):\n",
    "    if polaridad == 'Positiva':\n",
    "        return 1\n",
    "    if polaridad == \"Neutral\":\n",
    "        return 0\n",
    "    if polaridad == \"Negativa\":\n",
    "        return -1\n",
    "\n",
    "train[\"nLabel\"] = train[\"Label\"].apply(numerar_polaridad)\n",
    "test[\"nLabel\"] = test[\"Label\"].apply(numerar_polaridad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop(['date','Label','user_loc','Polaridad','Subjetividad','full_name','longitud_mensaje','palabras','country_code','geo_code','country','states','latitud','longitud'],axis=1 ,inplace=True)\n",
    "train.drop(['date','Label','user_loc','Polaridad','Subjetividad','full_name','longitud_mensaje','palabras','country_code','geo_code','country','states','latitud','longitud'],axis=1 ,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 8 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model: 0.680625 using {'bow__ngram_range': (1, 1), 'classifier__alpha': 0.01, 'tfidf__use_idf': False}\n",
      "\n",
      "\n",
      "Mean: 0.669375 Stdev:(0.026583) with: {'bow__ngram_range': (1, 1), 'classifier__alpha': 0.01, 'tfidf__use_idf': True}\n",
      "Mean: 0.680625 Stdev:(0.030033) with: {'bow__ngram_range': (1, 1), 'classifier__alpha': 0.01, 'tfidf__use_idf': False}\n",
      "Mean: 0.663750 Stdev:(0.019922) with: {'bow__ngram_range': (1, 1), 'classifier__alpha': 0.001, 'tfidf__use_idf': True}\n",
      "Mean: 0.674375 Stdev:(0.023791) with: {'bow__ngram_range': (1, 1), 'classifier__alpha': 0.001, 'tfidf__use_idf': False}\n",
      "Mean: 0.643750 Stdev:(0.030491) with: {'bow__ngram_range': (1, 2), 'classifier__alpha': 0.01, 'tfidf__use_idf': True}\n",
      "Mean: 0.658750 Stdev:(0.038951) with: {'bow__ngram_range': (1, 2), 'classifier__alpha': 0.01, 'tfidf__use_idf': False}\n",
      "Mean: 0.646250 Stdev:(0.030644) with: {'bow__ngram_range': (1, 2), 'classifier__alpha': 0.001, 'tfidf__use_idf': True}\n",
      "Mean: 0.655625 Stdev:(0.034737) with: {'bow__ngram_range': (1, 2), 'classifier__alpha': 0.001, 'tfidf__use_idf': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:    5.6s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "X_train, X_test, y_train, y_test = train_test_split(train['message'][:2000], train['nLabel'][:2000], test_size=0.2)\n",
    "\n",
    "\n",
    "# create pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('bow', CountVectorizer(strip_accents='ascii',\n",
    "                            stop_words='english',\n",
    "                            lowercase=True)),  # strings to token integer counts\n",
    "    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
    "    ('classifier', MultinomialNB()),  # train on TF-IDF vectors w/ Naive Bayes classifier\n",
    "])\n",
    "\n",
    "# this is where we define the values for GridSearchCV to iterate over\n",
    "parameters = {'bow__ngram_range': [(1, 1), (1, 2)],\n",
    "              'tfidf__use_idf': (True, False),\n",
    "              'classifier__alpha': (1e-2, 1e-3),\n",
    "             }\n",
    "\n",
    "# do 10-fold cross validation for each of the 6 possible combinations of the above params\n",
    "grid = GridSearchCV(pipeline, cv=10, param_grid=parameters, verbose=1)\n",
    "grid.fit(X_train,y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"\\nBest Model: %f using %s\" % (grid.best_score_, grid.best_params_))\n",
    "print('\\n')\n",
    "means = grid.cv_results_['mean_test_score']\n",
    "stds = grid.cv_results_['std_test_score']\n",
    "params = grid.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"Mean: %f Stdev:(%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./models/twitter_sentiment.pkl']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(grid, \"./models/twitter_sentiment.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:  0.6775\n",
      "\n",
      "\n",
      "confusion matrix: \n",
      " [[ 43  23  25]\n",
      " [  6 142  28]\n",
      " [ 10  37  86]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.73      0.47      0.57        91\n",
      "           0       0.70      0.81      0.75       176\n",
      "           1       0.62      0.65      0.63       133\n",
      "\n",
      "    accuracy                           0.68       400\n",
      "   macro avg       0.68      0.64      0.65       400\n",
      "weighted avg       0.68      0.68      0.67       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load from file and predict using the best configs found in the CV step\n",
    "model_NB = joblib.load(\"./models/twitter_sentiment.pkl\")\n",
    "\n",
    "# get predictions from best model above\n",
    "y_preds = model_NB.predict(X_test)\n",
    "\n",
    "print('accuracy score: ',accuracy_score(y_test, y_preds))\n",
    "print('\\n')\n",
    "print('confusion matrix: \\n',confusion_matrix(y_test,y_preds))\n",
    "print('\\n')\n",
    "print(classification_report(y_test, y_preds))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2504, 19)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_preds = model_NB.predict(sent['message'])\n",
    "\n",
    "# append predictions to dataframe\n",
    "df_tweet_preds = sent.copy()\n",
    "df_tweet_preds['predictions'] = tweet_preds\n",
    "df_tweet_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -- @rolandsmartin @Jillbiden46 @JoeBiden Biden was expos d to Trump and should be in quarantine. This is a grave error. \n",
      "\n",
      "0 -- @Jim_Jordan @realDonaldTrump @SpeakerPelosi @JoeBiden @EliseStefanik @DevinNunes @SenSchumer… https://t.co/qYCGkHjogS \n",
      "\n",
      "1 -- @glennkirschner2 @Michell45129550 @JoeBiden Joe Biden, like President Obama, will have to spend a large amount of t… https://t.co/8BDF1hKyS6 \n",
      "\n",
      "0 -- @gnuseibeh @realDonaldTrump @JoeBiden This is some bullshit. No one in the WH has followed the guidelines set and t… https://t.co/rvgMHCv5w4 \n",
      "\n",
      "1 -- @DeAnna4Congress I would say you are. Biden at least shows concern for Donald Trump and Masks do work. \n",
      "\n",
      "0 -- Michelle Obama's Closing Argument | Joe Biden For President 2020 https://t.co/A7SBruuHoS via @MichelleObama @JoeBiden \n",
      "\n",
      "0 -- @MikeBloomberg @voteblackpac @UniteCountryPAC @JoeBiden @KamalaHarris Buden/Harris is where our vote needs to be. S… https://t.co/uqSfTrk0Zo \n",
      "\n",
      "-1 -- @ABC13News @realDonaldTrump @JoeBiden Trump is lying as usual!  Biden owns guns! https://t.co/dul2Xmr8uE \n",
      "\n",
      "0 -- @TheDemocrats @JoeBiden 25th Amendment it to get rid of Dementia Biden!  Vote Trump! \n",
      "\n",
      "-1 -- @DanielNewman @DebraMessing Joe Biden upon hearing the unfortunate news aboutPOTUS contracting Covid,did not mock h… https://t.co/cmJxuVVoTq \n",
      "\n",
      "1 -- @JoeBiden Here's a slogan for you Joe Biden from a trump supporter if you're looking  Change back better \n",
      "\n",
      "1 -- @dcexaminer @JoeBiden @realDonaldTrump That was quick. And will be another sham where ABC claims Biden supporters a… https://t.co/CFKCSWLMp9 \n",
      "\n",
      "-1 -- @b_hoss_mac @JoeBiden @DrBiden Unfortunately, I think he will be. We’re screwed either way. Whether it’s Trump or B… https://t.co/B7caswVD99 \n",
      "\n",
      "-1 -- @alexsalvinews @AP We all know @realDonaldTrump is fine and not infected and @JoeBiden is trying desperately to get… https://t.co/En2wQCW1xJ \n",
      "\n",
      "0 -- SOMEONE CHECK ON @JoeBiden PLEASE!!!!! #fullmoon #COVID19 #biden #trump \n",
      "\n",
      "0 -- Harris: “On the issue of the economy, I don’t think there could be more or a fundamental difference than Donald Trump and Joe Biden.” \n",
      "\n",
      "1 -- Did Donald Trump infect all his kids, his staff, security and others?\n",
      "\n",
      "What an asshole.\n",
      "\n",
      "I hope that he didn't infect Biden. \n",
      "\n",
      "0 -- President Donald Trump has refused to take part in a virtual TV debate with his Democratic rival Joe Biden: https://t.co/9BT5QM9ovM \n",
      "\n",
      "0 -- @jrgaillot @JoeBiden Trump hasn’t. Why should future President Joe Biden? \n",
      "\n",
      "1 -- @JoeBiden Yes sir joe Biden, you better be careful !! you don’t catch the Covid !! I don’t think you would make it Joe!! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "# print text and sentiment\n",
    "\n",
    "index = random.sample(range(tweet_preds.shape[0]), 20)\n",
    "for text, sentiment in zip(df_tweet_preds.message[index],\n",
    "                           df_tweet_preds.predictions[index]):\n",
    "    print (sentiment, '--', text, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_name</th>\n",
       "      <th>message</th>\n",
       "      <th>refinado</th>\n",
       "      <th>nLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>susanha77835097</td>\n",
       "      <td>@blossomingabyss @JoeBiden He filled his pocke...</td>\n",
       "      <td>['filled', 'pocketskids', 'familyharris', 'unq...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tomborelli</td>\n",
       "      <td>Supporting @JoeBiden means packing the Supreme...</td>\n",
       "      <td>['supporting', 'means', 'packing', 'supreme', ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>John_Di_Lemme</td>\n",
       "      <td>@ABC13News @realDonaldTrump @JoeBiden Nancy Pe...</td>\n",
       "      <td>['nancy', 'pelosi', 'nuts', 'joe', 'biden', 'k...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Parnell_100</td>\n",
       "      <td>@JoeBiden There is NO STOPPING this AMERICAN T...</td>\n",
       "      <td>['stopping', 'american', 'trinity', 'train', '...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sqlblues</td>\n",
       "      <td>@FenrirWolf26 @Stanhope2011VJ Britons have als...</td>\n",
       "      <td>['britons', 'also', 'pumped', 'relentless', 'd...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_name                                            message  \\\n",
       "0  susanha77835097  @blossomingabyss @JoeBiden He filled his pocke...   \n",
       "1       tomborelli  Supporting @JoeBiden means packing the Supreme...   \n",
       "2    John_Di_Lemme  @ABC13News @realDonaldTrump @JoeBiden Nancy Pe...   \n",
       "3      Parnell_100  @JoeBiden There is NO STOPPING this AMERICAN T...   \n",
       "4         sqlblues  @FenrirWolf26 @Stanhope2011VJ Britons have als...   \n",
       "\n",
       "                                            refinado  nLabel  \n",
       "0  ['filled', 'pocketskids', 'familyharris', 'unq...       1  \n",
       "1  ['supporting', 'means', 'packing', 'supreme', ...       1  \n",
       "2  ['nancy', 'pelosi', 'nuts', 'joe', 'biden', 'k...       0  \n",
       "3  ['stopping', 'american', 'trinity', 'train', '...       0  \n",
       "4  ['britons', 'also', 'pumped', 'relentless', 'd...      -1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train=pd.get_dummies(data=train, columns=['nLabel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "\n",
    "def polarity_scores_all(tweet):\n",
    "  '''\n",
    "  Takes string of text to:\n",
    "  1. Gets sentiment metrics\n",
    "  2. Returns negative, neutral, positive \n",
    "  and compound scores as lists.\n",
    "  '''\n",
    "  neg, neu, pos, compound = [], [], [], []\n",
    "  analyser = SentimentIntensityAnalyzer()\n",
    "  \n",
    "  for message in tweet:\n",
    "    dict_ = analyser.polarity_scores(message)\n",
    "    neg.append(dict_['neg'])\n",
    "    neu.append(dict_['neu'])\n",
    "    pos.append(dict_['pos'])\n",
    "    compound.append(dict_['compound'])\n",
    "  \n",
    "  return neg, neu, pos, compound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_name</th>\n",
       "      <th>message</th>\n",
       "      <th>refinado</th>\n",
       "      <th>nLabel</th>\n",
       "      <th>neg_scores</th>\n",
       "      <th>neu_scores</th>\n",
       "      <th>pos_scores</th>\n",
       "      <th>compound_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>susanha77835097</td>\n",
       "      <td>@blossomingabyss @JoeBiden He filled his pocke...</td>\n",
       "      <td>['filled', 'pocketskids', 'familyharris', 'unq...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tomborelli</td>\n",
       "      <td>Supporting @JoeBiden means packing the Supreme...</td>\n",
       "      <td>['supporting', 'means', 'packing', 'supreme', ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.7579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>John_Di_Lemme</td>\n",
       "      <td>@ABC13News @realDonaldTrump @JoeBiden Nancy Pe...</td>\n",
       "      <td>['nancy', 'pelosi', 'nuts', 'joe', 'biden', 'k...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.3182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Parnell_100</td>\n",
       "      <td>@JoeBiden There is NO STOPPING this AMERICAN T...</td>\n",
       "      <td>['stopping', 'american', 'trinity', 'train', '...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.1531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sqlblues</td>\n",
       "      <td>@FenrirWolf26 @Stanhope2011VJ Britons have als...</td>\n",
       "      <td>['britons', 'also', 'pumped', 'relentless', 'd...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.339</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.110</td>\n",
       "      <td>-0.5423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>_walkforACure</td>\n",
       "      <td>US presidential debate officially cancelled\\n\\...</td>\n",
       "      <td>['presidential', 'debate', 'officially', 'canc...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>newollien</td>\n",
       "      <td>@blossomingabyss @JoeBiden Oh behave, you tit....</td>\n",
       "      <td>['behave', 'tit', 'trump', 'tactic', 'debate',...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.619</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.5719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AIPCMaha</td>\n",
       "      <td>Joe Biden is surging in the battle for the Whi...</td>\n",
       "      <td>['joe', 'biden', 'surging', 'battle', 'white',...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.3818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RonnieMro</td>\n",
       "      <td>We know exactly what we’re getting with Donald...</td>\n",
       "      <td>['know', 'exactly', 'getting', 'donald', 'trum...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cyn507</td>\n",
       "      <td>Looks like @realDonaldTrump is running scared....</td>\n",
       "      <td>['looks', 'like', 'running', 'scared', 'bag', ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.341</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.194</td>\n",
       "      <td>-0.2263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_name                                            message  \\\n",
       "0  susanha77835097  @blossomingabyss @JoeBiden He filled his pocke...   \n",
       "1       tomborelli  Supporting @JoeBiden means packing the Supreme...   \n",
       "2    John_Di_Lemme  @ABC13News @realDonaldTrump @JoeBiden Nancy Pe...   \n",
       "3      Parnell_100  @JoeBiden There is NO STOPPING this AMERICAN T...   \n",
       "4         sqlblues  @FenrirWolf26 @Stanhope2011VJ Britons have als...   \n",
       "5    _walkforACure  US presidential debate officially cancelled\\n\\...   \n",
       "6        newollien  @blossomingabyss @JoeBiden Oh behave, you tit....   \n",
       "7         AIPCMaha  Joe Biden is surging in the battle for the Whi...   \n",
       "8        RonnieMro  We know exactly what we’re getting with Donald...   \n",
       "9           cyn507  Looks like @realDonaldTrump is running scared....   \n",
       "\n",
       "                                            refinado  nLabel  neg_scores  \\\n",
       "0  ['filled', 'pocketskids', 'familyharris', 'unq...       1       0.000   \n",
       "1  ['supporting', 'means', 'packing', 'supreme', ...       1       0.000   \n",
       "2  ['nancy', 'pelosi', 'nuts', 'joe', 'biden', 'k...       0       0.247   \n",
       "3  ['stopping', 'american', 'trinity', 'train', '...       0       0.167   \n",
       "4  ['britons', 'also', 'pumped', 'relentless', 'd...      -1       0.339   \n",
       "5  ['presidential', 'debate', 'officially', 'canc...       0       0.286   \n",
       "6  ['behave', 'tit', 'trump', 'tactic', 'debate',...       0       0.381   \n",
       "7  ['joe', 'biden', 'surging', 'battle', 'white',...      -1       0.206   \n",
       "8  ['know', 'exactly', 'getting', 'donald', 'trum...      -1       0.000   \n",
       "9  ['looks', 'like', 'running', 'scared', 'bag', ...       0       0.341   \n",
       "\n",
       "   neu_scores  pos_scores  compound_scores  \n",
       "0       1.000       0.000           0.0000  \n",
       "1       0.552       0.448           0.7579  \n",
       "2       0.753       0.000          -0.3182  \n",
       "3       0.833       0.000          -0.1531  \n",
       "4       0.550       0.110          -0.5423  \n",
       "5       0.714       0.000          -0.2500  \n",
       "6       0.619       0.000          -0.5719  \n",
       "7       0.794       0.000          -0.3818  \n",
       "8       1.000       0.000           0.0000  \n",
       "9       0.465       0.194          -0.2263  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores = polarity_scores_all(train.refinado.values)\n",
    "train['neg_scores'] = all_scores[0]\n",
    "train['neu_scores'] = all_scores[1]\n",
    "train['pos_scores'] = all_scores[2]\n",
    "train['compound_scores'] = all_scores[3]\n",
    "\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_family = {  \n",
    "    'NOUN' : ['NN','NNS','NNP'], # Removed 'NNPS'\n",
    "    'PRON' : ['PRP','PRP$','WP'],\n",
    "    'VERB' : ['VB','VBD','VBG','VBN','VBP','VBZ'],\n",
    "    'ADJ' :  ['JJ','JJR','JJS'],\n",
    "    'ADV' : ['RB','RBR','RBS','WRB']\n",
    "}\n",
    "\n",
    "def count_pos_tag(tweets):\n",
    "  '''\n",
    "  Takes string of text to:\n",
    "  1. Processes text and attaches POS tags\n",
    "  2. Input the dictionary of POS tags into a Counter.\n",
    "  2. Returns list of POS tags with occurrence number '''\n",
    "  total_count = []\n",
    "  for s in tweets:\n",
    "    partial_count = {}\n",
    "    s = s.split()\n",
    "    count_pos = Counter(dict(nltk.pos_tag(s)).values())\n",
    "    \n",
    "    for item, value in count_pos.items():\n",
    "      partial_count[item] = partial_count.get(item, 0) + 1\n",
    "            \n",
    "    total_count.append(partial_count)\n",
    "\n",
    "  return total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.reindex of        RB  VBZ  PRP  VBD  PRP$  NNS   NN  VBN  PDT   DT  ...  NNPS  UH  RBR  \\\n",
       "0     1.0  1.0  1.0  1.0   1.0  1.0  1.0  1.0  1.0  1.0  ...   NaN NaN  NaN   \n",
       "1     1.0  NaN  NaN  NaN   NaN  1.0  1.0  NaN  NaN  1.0  ...   NaN NaN  NaN   \n",
       "2     NaN  NaN  NaN  NaN   NaN  1.0  1.0  NaN  NaN  NaN  ...   NaN NaN  NaN   \n",
       "3     NaN  1.0  NaN  NaN   NaN  1.0  1.0  NaN  NaN  1.0  ...   NaN NaN  NaN   \n",
       "4     1.0  NaN  NaN  NaN   NaN  1.0  1.0  1.0  NaN  1.0  ...   NaN NaN  NaN   \n",
       "...   ...  ...  ...  ...   ...  ...  ...  ...  ...  ...  ...   ...  ..  ...   \n",
       "2499  1.0  NaN  1.0  1.0   NaN  NaN  1.0  NaN  NaN  1.0  ...   NaN NaN  NaN   \n",
       "2500  NaN  1.0  1.0  NaN   NaN  NaN  1.0  NaN  1.0  1.0  ...   NaN NaN  NaN   \n",
       "2501  NaN  NaN  1.0  1.0   NaN  NaN  1.0  NaN  NaN  1.0  ...   NaN NaN  NaN   \n",
       "2502  NaN  NaN  NaN  NaN   NaN  NaN  1.0  NaN  NaN  1.0  ...   NaN NaN  NaN   \n",
       "2503  1.0  NaN  1.0  1.0   NaN  1.0  1.0  NaN  NaN  1.0  ...   NaN NaN  NaN   \n",
       "\n",
       "       (   $  LS  POS  FW  SYM  ''  \n",
       "0    NaN NaN NaN  NaN NaN  NaN NaN  \n",
       "1    NaN NaN NaN  NaN NaN  NaN NaN  \n",
       "2    NaN NaN NaN  NaN NaN  NaN NaN  \n",
       "3    NaN NaN NaN  NaN NaN  NaN NaN  \n",
       "4    NaN NaN NaN  NaN NaN  NaN NaN  \n",
       "...   ..  ..  ..  ...  ..  ...  ..  \n",
       "2499 NaN NaN NaN  NaN NaN  NaN NaN  \n",
       "2500 NaN NaN NaN  NaN NaN  NaN NaN  \n",
       "2501 NaN NaN NaN  NaN NaN  NaN NaN  \n",
       "2502 NaN NaN NaN  NaN NaN  NaN NaN  \n",
       "2503 NaN NaN NaN  NaN NaN  NaN NaN  \n",
       "\n",
       "[2504 rows x 41 columns]>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve POS tags with occurrence \n",
    "total_count = count_pos_tag(train.message.values)\n",
    "# As dataframe \n",
    "pos_df = pd.DataFrame(total_count)\n",
    "# Remove unwanted characters\n",
    "# Inspection\n",
    "pos_df.reindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pos_df['NOUN'] = pos_df[pos_family['NOUN']].sum(axis=1)\n",
    "pos_df['PRON'] = pos_df[pos_family['PRON']].sum(axis=1)\n",
    "pos_df['VERB'] = pos_df[pos_family['VERB']].sum(axis=1)\n",
    "pos_df['ADJ'] = pos_df[pos_family['ADJ']].sum(axis=1)\n",
    "pos_df['ADV'] = pos_df[pos_family['ADV']].sum(axis=1)\n",
    "\n",
    "pos_df = pos_df[['NOUN', 'PRON', 'VERB', 'ADJ', 'ADV']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_name</th>\n",
       "      <th>message</th>\n",
       "      <th>refinado</th>\n",
       "      <th>nLabel</th>\n",
       "      <th>neg_scores</th>\n",
       "      <th>neu_scores</th>\n",
       "      <th>pos_scores</th>\n",
       "      <th>compound_scores</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>PRON</th>\n",
       "      <th>VERB</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>ADV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>susanha77835097</td>\n",
       "      <td>@blossomingabyss @JoeBiden He filled his pocke...</td>\n",
       "      <td>['filled', 'pocketskids', 'familyharris', 'unq...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tomborelli</td>\n",
       "      <td>Supporting @JoeBiden means packing the Supreme...</td>\n",
       "      <td>['supporting', 'means', 'packing', 'supreme', ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.7579</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>John_Di_Lemme</td>\n",
       "      <td>@ABC13News @realDonaldTrump @JoeBiden Nancy Pe...</td>\n",
       "      <td>['nancy', 'pelosi', 'nuts', 'joe', 'biden', 'k...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.3182</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Parnell_100</td>\n",
       "      <td>@JoeBiden There is NO STOPPING this AMERICAN T...</td>\n",
       "      <td>['stopping', 'american', 'trinity', 'train', '...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.1531</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sqlblues</td>\n",
       "      <td>@FenrirWolf26 @Stanhope2011VJ Britons have als...</td>\n",
       "      <td>['britons', 'also', 'pumped', 'relentless', 'd...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.339</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.110</td>\n",
       "      <td>-0.5423</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>JojoAkoto</td>\n",
       "      <td>Great debate between Donald Trump and Joe Bide...</td>\n",
       "      <td>['great', 'debate', 'donald', 'trump', 'joe', ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.9287</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2500</th>\n",
       "      <td>Crackerthe4th</td>\n",
       "      <td>To all the undecided voters: the biggest sprea...</td>\n",
       "      <td>['undecided', 'voters', 'big', 'spreader', 'mi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.339</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2501</th>\n",
       "      <td>ThomasCagganel1</td>\n",
       "      <td>@thebradfordfile Chris Wallace went after Dona...</td>\n",
       "      <td>['chris', 'wallace', 'went', 'donald', 'trump'...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.662</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.1531</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2502</th>\n",
       "      <td>Hal4</td>\n",
       "      <td>https://t.co/faYZgsey1P Something #good for a ...</td>\n",
       "      <td>['something', 'good', 'change']</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2503</th>\n",
       "      <td>SmarshMary</td>\n",
       "      <td>@digwarrior4kids @JeSuisASDAR @JoeBiden @Speak...</td>\n",
       "      <td>['wanted', 'economy', 'closed', 'say']</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2504 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            user_name                                            message  \\\n",
       "0     susanha77835097  @blossomingabyss @JoeBiden He filled his pocke...   \n",
       "1          tomborelli  Supporting @JoeBiden means packing the Supreme...   \n",
       "2       John_Di_Lemme  @ABC13News @realDonaldTrump @JoeBiden Nancy Pe...   \n",
       "3         Parnell_100  @JoeBiden There is NO STOPPING this AMERICAN T...   \n",
       "4            sqlblues  @FenrirWolf26 @Stanhope2011VJ Britons have als...   \n",
       "...               ...                                                ...   \n",
       "2499        JojoAkoto  Great debate between Donald Trump and Joe Bide...   \n",
       "2500    Crackerthe4th  To all the undecided voters: the biggest sprea...   \n",
       "2501  ThomasCagganel1  @thebradfordfile Chris Wallace went after Dona...   \n",
       "2502             Hal4  https://t.co/faYZgsey1P Something #good for a ...   \n",
       "2503       SmarshMary  @digwarrior4kids @JeSuisASDAR @JoeBiden @Speak...   \n",
       "\n",
       "                                               refinado  nLabel  neg_scores  \\\n",
       "0     ['filled', 'pocketskids', 'familyharris', 'unq...       1       0.000   \n",
       "1     ['supporting', 'means', 'packing', 'supreme', ...       1       0.000   \n",
       "2     ['nancy', 'pelosi', 'nuts', 'joe', 'biden', 'k...       0       0.247   \n",
       "3     ['stopping', 'american', 'trinity', 'train', '...       0       0.167   \n",
       "4     ['britons', 'also', 'pumped', 'relentless', 'd...      -1       0.339   \n",
       "...                                                 ...     ...         ...   \n",
       "2499  ['great', 'debate', 'donald', 'trump', 'joe', ...       1       0.000   \n",
       "2500  ['undecided', 'voters', 'big', 'spreader', 'mi...       0       0.339   \n",
       "2501  ['chris', 'wallace', 'went', 'donald', 'trump'...       0       0.147   \n",
       "2502                    ['something', 'good', 'change']       1       0.000   \n",
       "2503             ['wanted', 'economy', 'closed', 'say']      -1       0.000   \n",
       "\n",
       "      neu_scores  pos_scores  compound_scores  NOUN  PRON  VERB  ADJ  ADV  \n",
       "0          1.000       0.000           0.0000   3.0   2.0   4.0  0.0  1.0  \n",
       "1          0.552       0.448           0.7579   3.0   0.0   2.0  1.0  1.0  \n",
       "2          0.753       0.000          -0.3182   3.0   0.0   1.0  1.0  0.0  \n",
       "3          0.833       0.000          -0.1531   3.0   0.0   2.0  0.0  0.0  \n",
       "4          0.550       0.110          -0.5423   3.0   0.0   2.0  1.0  1.0  \n",
       "...          ...         ...              ...   ...   ...   ...  ...  ...  \n",
       "2499       0.305       0.695           0.9287   2.0   1.0   2.0  2.0  1.0  \n",
       "2500       0.403       0.258           0.0000   2.0   1.0   1.0  2.0  0.0  \n",
       "2501       0.662       0.191           0.1531   2.0   1.0   2.0  1.0  0.0  \n",
       "2502       0.408       0.592           0.4404   1.0   0.0   1.0  1.0  0.0  \n",
       "2503       1.000       0.000           0.0000   3.0   1.0   3.0  1.0  1.0  \n",
       "\n",
       "[2504 rows x 13 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.concat([train, pos_df], axis = 1)\n",
    "train = train.fillna(value=0.0)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop_duplicates(subset=['message'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2495 entries, 0 to 2503\n",
      "Data columns (total 13 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   user_name        2495 non-null   object \n",
      " 1   message          2495 non-null   object \n",
      " 2   refinado         2495 non-null   object \n",
      " 3   nLabel           2495 non-null   int64  \n",
      " 4   neg_scores       2495 non-null   float64\n",
      " 5   neu_scores       2495 non-null   float64\n",
      " 6   pos_scores       2495 non-null   float64\n",
      " 7   compound_scores  2495 non-null   float64\n",
      " 8   NOUN             2495 non-null   float64\n",
      " 9   PRON             2495 non-null   float64\n",
      " 10  VERB             2495 non-null   float64\n",
      " 11  ADJ              2495 non-null   float64\n",
      " 12  ADV              2495 non-null   float64\n",
      "dtypes: float64(9), int64(1), object(3)\n",
      "memory usage: 272.9+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_name</th>\n",
       "      <th>message</th>\n",
       "      <th>refinado</th>\n",
       "      <th>nLabel</th>\n",
       "      <th>neg_scores</th>\n",
       "      <th>neu_scores</th>\n",
       "      <th>pos_scores</th>\n",
       "      <th>compound_scores</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>PRON</th>\n",
       "      <th>VERB</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>ADV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>susanha77835097</td>\n",
       "      <td>@blossomingabyss @JoeBiden He filled his pocke...</td>\n",
       "      <td>['filled', 'pocketskids', 'familyharris', 'unq...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tomborelli</td>\n",
       "      <td>Supporting @JoeBiden means packing the Supreme...</td>\n",
       "      <td>['supporting', 'means', 'packing', 'supreme', ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.7579</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>John_Di_Lemme</td>\n",
       "      <td>@ABC13News @realDonaldTrump @JoeBiden Nancy Pe...</td>\n",
       "      <td>['nancy', 'pelosi', 'nuts', 'joe', 'biden', 'k...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.3182</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Parnell_100</td>\n",
       "      <td>@JoeBiden There is NO STOPPING this AMERICAN T...</td>\n",
       "      <td>['stopping', 'american', 'trinity', 'train', '...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.1531</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sqlblues</td>\n",
       "      <td>@FenrirWolf26 @Stanhope2011VJ Britons have als...</td>\n",
       "      <td>['britons', 'also', 'pumped', 'relentless', 'd...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.339</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.110</td>\n",
       "      <td>-0.5423</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>_walkforACure</td>\n",
       "      <td>US presidential debate officially cancelled\\n\\...</td>\n",
       "      <td>['presidential', 'debate', 'officially', 'canc...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.2500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>newollien</td>\n",
       "      <td>@blossomingabyss @JoeBiden Oh behave, you tit....</td>\n",
       "      <td>['behave', 'tit', 'trump', 'tactic', 'debate',...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.619</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.5719</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AIPCMaha</td>\n",
       "      <td>Joe Biden is surging in the battle for the Whi...</td>\n",
       "      <td>['joe', 'biden', 'surging', 'battle', 'white',...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.3818</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RonnieMro</td>\n",
       "      <td>We know exactly what we’re getting with Donald...</td>\n",
       "      <td>['know', 'exactly', 'getting', 'donald', 'trum...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cyn507</td>\n",
       "      <td>Looks like @realDonaldTrump is running scared....</td>\n",
       "      <td>['looks', 'like', 'running', 'scared', 'bag', ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.341</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.194</td>\n",
       "      <td>-0.2263</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_name                                            message  \\\n",
       "0  susanha77835097  @blossomingabyss @JoeBiden He filled his pocke...   \n",
       "1       tomborelli  Supporting @JoeBiden means packing the Supreme...   \n",
       "2    John_Di_Lemme  @ABC13News @realDonaldTrump @JoeBiden Nancy Pe...   \n",
       "3      Parnell_100  @JoeBiden There is NO STOPPING this AMERICAN T...   \n",
       "4         sqlblues  @FenrirWolf26 @Stanhope2011VJ Britons have als...   \n",
       "5    _walkforACure  US presidential debate officially cancelled\\n\\...   \n",
       "6        newollien  @blossomingabyss @JoeBiden Oh behave, you tit....   \n",
       "7         AIPCMaha  Joe Biden is surging in the battle for the Whi...   \n",
       "8        RonnieMro  We know exactly what we’re getting with Donald...   \n",
       "9           cyn507  Looks like @realDonaldTrump is running scared....   \n",
       "\n",
       "                                            refinado  nLabel  neg_scores  \\\n",
       "0  ['filled', 'pocketskids', 'familyharris', 'unq...       1       0.000   \n",
       "1  ['supporting', 'means', 'packing', 'supreme', ...       1       0.000   \n",
       "2  ['nancy', 'pelosi', 'nuts', 'joe', 'biden', 'k...       0       0.247   \n",
       "3  ['stopping', 'american', 'trinity', 'train', '...       0       0.167   \n",
       "4  ['britons', 'also', 'pumped', 'relentless', 'd...      -1       0.339   \n",
       "5  ['presidential', 'debate', 'officially', 'canc...       0       0.286   \n",
       "6  ['behave', 'tit', 'trump', 'tactic', 'debate',...       0       0.381   \n",
       "7  ['joe', 'biden', 'surging', 'battle', 'white',...      -1       0.206   \n",
       "8  ['know', 'exactly', 'getting', 'donald', 'trum...      -1       0.000   \n",
       "9  ['looks', 'like', 'running', 'scared', 'bag', ...       0       0.341   \n",
       "\n",
       "   neu_scores  pos_scores  compound_scores  NOUN  PRON  VERB  ADJ  ADV  \n",
       "0       1.000       0.000           0.0000   3.0   2.0   4.0  0.0  1.0  \n",
       "1       0.552       0.448           0.7579   3.0   0.0   2.0  1.0  1.0  \n",
       "2       0.753       0.000          -0.3182   3.0   0.0   1.0  1.0  0.0  \n",
       "3       0.833       0.000          -0.1531   3.0   0.0   2.0  0.0  0.0  \n",
       "4       0.550       0.110          -0.5423   3.0   0.0   2.0  1.0  1.0  \n",
       "5       0.714       0.000          -0.2500   2.0   1.0   1.0  1.0  1.0  \n",
       "6       0.619       0.000          -0.5719   2.0   1.0   4.0  1.0  1.0  \n",
       "7       0.794       0.000          -0.3818   3.0   0.0   3.0  1.0  0.0  \n",
       "8       1.000       0.000           0.0000   2.0   2.0   4.0  2.0  1.0  \n",
       "9       0.465       0.194          -0.2263   2.0   2.0   4.0  0.0  0.0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('./Outputs/feat_train_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_name</th>\n",
       "      <th>message</th>\n",
       "      <th>refinado</th>\n",
       "      <th>nLabel</th>\n",
       "      <th>neg_scores</th>\n",
       "      <th>neu_scores</th>\n",
       "      <th>pos_scores</th>\n",
       "      <th>compound_scores</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>PRON</th>\n",
       "      <th>VERB</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>ADV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>susanha77835097</td>\n",
       "      <td>@blossomingabyss @JoeBiden He filled his pocke...</td>\n",
       "      <td>['filled', 'pocketskids', 'familyharris', 'unq...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tomborelli</td>\n",
       "      <td>Supporting @JoeBiden means packing the Supreme...</td>\n",
       "      <td>['supporting', 'means', 'packing', 'supreme', ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.7579</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>John_Di_Lemme</td>\n",
       "      <td>@ABC13News @realDonaldTrump @JoeBiden Nancy Pe...</td>\n",
       "      <td>['nancy', 'pelosi', 'nuts', 'joe', 'biden', 'k...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.3182</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Parnell_100</td>\n",
       "      <td>@JoeBiden There is NO STOPPING this AMERICAN T...</td>\n",
       "      <td>['stopping', 'american', 'trinity', 'train', '...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.1531</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sqlblues</td>\n",
       "      <td>@FenrirWolf26 @Stanhope2011VJ Britons have als...</td>\n",
       "      <td>['britons', 'also', 'pumped', 'relentless', 'd...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.339</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.110</td>\n",
       "      <td>-0.5423</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_name                                            message  \\\n",
       "0  susanha77835097  @blossomingabyss @JoeBiden He filled his pocke...   \n",
       "1       tomborelli  Supporting @JoeBiden means packing the Supreme...   \n",
       "2    John_Di_Lemme  @ABC13News @realDonaldTrump @JoeBiden Nancy Pe...   \n",
       "3      Parnell_100  @JoeBiden There is NO STOPPING this AMERICAN T...   \n",
       "4         sqlblues  @FenrirWolf26 @Stanhope2011VJ Britons have als...   \n",
       "\n",
       "                                            refinado  nLabel  neg_scores  \\\n",
       "0  ['filled', 'pocketskids', 'familyharris', 'unq...       1       0.000   \n",
       "1  ['supporting', 'means', 'packing', 'supreme', ...       1       0.000   \n",
       "2  ['nancy', 'pelosi', 'nuts', 'joe', 'biden', 'k...       0       0.247   \n",
       "3  ['stopping', 'american', 'trinity', 'train', '...       0       0.167   \n",
       "4  ['britons', 'also', 'pumped', 'relentless', 'd...      -1       0.339   \n",
       "\n",
       "   neu_scores  pos_scores  compound_scores  NOUN  PRON  VERB  ADJ  ADV  \n",
       "0       1.000       0.000           0.0000   3.0   2.0   4.0  0.0  1.0  \n",
       "1       0.552       0.448           0.7579   3.0   0.0   2.0  1.0  1.0  \n",
       "2       0.753       0.000          -0.3182   3.0   0.0   1.0  1.0  0.0  \n",
       "3       0.833       0.000          -0.1531   3.0   0.0   2.0  0.0  0.0  \n",
       "4       0.550       0.110          -0.5423   3.0   0.0   2.0  1.0  1.0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().values.any()\n",
    "train_prep=train.copy()\n",
    "train_prep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2495, 5), (2495, 1))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting Features\n",
    "features = ['message', 'neu_scores', 'neg_scores', 'compound_scores', 'pos_scores']\n",
    "label = ['nLabel']\n",
    "# Saving features and label data in X and y for train-test split\n",
    "X = train_prep[[col for col in train_prep.columns if col in features]]\n",
    "y = train_prep[label]\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes are (1746, 5) and (749, 5)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "print(\"Shapes are {} and {}\".format(X_train.shape, X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0    0.457045\n",
       " 1    0.310424\n",
       "-1    0.232532\n",
       "dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_train.values.ravel()).value_counts(normalize=True)\n",
    "pd.Series(y_train.values.ravel()).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## El dataset tiene un 45% de acertar si un mensaje es neutro, 31% si es positivo y un 23% de acertar si es negativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "class TextSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    Use on text columns in the data\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[self.key]\n",
    "    \n",
    "class NumberSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    Use on numeric columns in the data\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[[self.key]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline to convert tweets to a matrix of TF-IDF features.\n",
    "tfidf = Pipeline([\n",
    "                ('selector', TextSelector(key='message')),\n",
    "                ('tfidf', TfidfVectorizer())\n",
    "            ])\n",
    "\n",
    "# Pipeline to convert tweets to a matrix of token counts\n",
    "countvect = Pipeline([\n",
    "                ('selector', TextSelector(key='message')),\n",
    "                ('countvect', CountVectorizer())\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Applying tfidf anf countvec to features\n",
    "\n",
    "neu_scores =  Pipeline([\n",
    "                ('selector', NumberSelector(key='neu_scores')),\n",
    "                ('minmax', MinMaxScaler())\n",
    "            ])\n",
    "neg_scores =  Pipeline([\n",
    "                ('selector', NumberSelector(key='neg_scores')),\n",
    "                ('minmax', MinMaxScaler())\n",
    "            ])\n",
    "pos_scores =  Pipeline([\n",
    "                ('selector', NumberSelector(key='pos_scores')),\n",
    "                ('minmax', MinMaxScaler())\n",
    "            ])\n",
    "\n",
    "compound_scores =  Pipeline([\n",
    "                ('selector', NumberSelector(key='compound_scores')),\n",
    "                ('minmax', MinMaxScaler())\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# defining different sets of text processors\n",
    "def features_union(textProcessor):\n",
    "    return FeatureUnion([('text', textProcessor),\n",
    "                      ('neu_scores', neu_scores),\n",
    "                      ('neg_scores', neg_scores),\n",
    "                      ('pos_scores', pos_scores),\n",
    "                      ('compound_scores', compound_scores)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-e8fb4afa7a8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder().fit(y_train.values.ravel())\n",
    "\n",
    "y_train = le.transform(y_train.values.ravel())\n",
    "y_test = le.transform(y_test.values.ravel())\n",
    "\n",
    "X_train.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificador Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6995994659546061"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate classifier\n",
    "clf = MultinomialNB()\n",
    "\n",
    "# combine features\n",
    "features_count = features_union(countvect)\n",
    "\n",
    "# define pipeline object \n",
    "nb_pipeline = Pipeline([('features', features_count),\n",
    "                       ('nb', clf)])\n",
    "\n",
    "# Fit classifier\n",
    "nb_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# score\n",
    "nb_pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support vector machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7543391188251002"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate classifier\n",
    "svm = LinearSVC()\n",
    "\n",
    "#  combine features\n",
    "features_tfidf = features_union(tfidf)\n",
    "\n",
    "# define pipeline object\n",
    "svm_pipeline = Pipeline([('features', features_tfidf),\n",
    "                       ('svm', svm)])\n",
    "\n",
    "# Fit classifier\n",
    "svm_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# score\n",
    "svm_pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Naive Bayes Classifier\n",
    "\n",
    "# combine features\n",
    "features_tfidf = features_union(tfidf)\n",
    "\n",
    "# instantiate pipeline object\n",
    "nb_pipeline = Pipeline([('feats', features_tfidf),  ('clf', MultinomialNB())])\n",
    "\n",
    "# parameter grid (3x3x2x2x3x3x2) combinations\n",
    "parameters = {\n",
    "    'feats__text__tfidf__max_df': (0.5, 0.75, 1.0),\n",
    "    'feats__text__tfidf__ngram_range': ((1, 1), (1, 2), (2, 2)), \n",
    "    'feats__text__tfidf__use_idf': (False, True),\n",
    "    'feats__text__tfidf__binary':(False, True),\n",
    "    'feats__text__tfidf__binary':('l1', 'l2', None),\n",
    "    'clf__alpha': (1.0, 5.0, 10.0),\n",
    "    'clf__fit_prior': (True, False),     \n",
    "}\n",
    "\n",
    "# instantiate GridSearchCV object with pipeline and parameters with 3-folds cross-validation\n",
    "nb_grid = GridSearchCV(nb_pipeline, parameters, cv=3) # this takes a while :/\n",
    "\n",
    "# start time \n",
    "nb_start = time.time()\n",
    "\n",
    "# Fit \n",
    "nb_grid.fit(X_train, y_train)\n",
    "\n",
    "# end time \n",
    "svm_end = time.time()\n",
    "print(f\"Time taken to run: {round((svm_end - nb_start)/60,1)} minutes\")\n",
    "\n",
    "# Check score\n",
    "nb_grid.score(X_test, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'clf__alpha': 1.0, 'clf__fit_prior': False, 'feats__text__tfidf__binary': 'l1', 'feats__text__tfidf__max_df': 0.5, 'feats__text__tfidf__ngram_range': (1, 1), 'feats__text__tfidf__use_idf': True}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_clf__alpha</th>\n",
       "      <th>param_clf__fit_prior</th>\n",
       "      <th>param_feats__text__tfidf__binary</th>\n",
       "      <th>param_feats__text__tfidf__max_df</th>\n",
       "      <th>param_feats__text__tfidf__ngram_range</th>\n",
       "      <th>param_feats__text__tfidf__use_idf</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.046393</td>\n",
       "      <td>0.002797</td>\n",
       "      <td>0.019311</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>{'clf__alpha': 1.0, 'clf__fit_prior': True, 'f...</td>\n",
       "      <td>0.575601</td>\n",
       "      <td>0.546392</td>\n",
       "      <td>0.560137</td>\n",
       "      <td>0.560710</td>\n",
       "      <td>0.011932</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.045267</td>\n",
       "      <td>0.001148</td>\n",
       "      <td>0.020197</td>\n",
       "      <td>0.000960</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>{'clf__alpha': 1.0, 'clf__fit_prior': True, 'f...</td>\n",
       "      <td>0.597938</td>\n",
       "      <td>0.551546</td>\n",
       "      <td>0.587629</td>\n",
       "      <td>0.579038</td>\n",
       "      <td>0.019890</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.079374</td>\n",
       "      <td>0.003512</td>\n",
       "      <td>0.025655</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>{'clf__alpha': 1.0, 'clf__fit_prior': True, 'f...</td>\n",
       "      <td>0.548110</td>\n",
       "      <td>0.530928</td>\n",
       "      <td>0.532646</td>\n",
       "      <td>0.537228</td>\n",
       "      <td>0.007727</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.046393      0.002797         0.019311        0.000327   \n",
       "1       0.045267      0.001148         0.020197        0.000960   \n",
       "2       0.079374      0.003512         0.025655        0.000415   \n",
       "\n",
       "  param_clf__alpha param_clf__fit_prior param_feats__text__tfidf__binary  \\\n",
       "0                1                 True                               l1   \n",
       "1                1                 True                               l1   \n",
       "2                1                 True                               l1   \n",
       "\n",
       "  param_feats__text__tfidf__max_df param_feats__text__tfidf__ngram_range  \\\n",
       "0                              0.5                                (1, 1)   \n",
       "1                              0.5                                (1, 1)   \n",
       "2                              0.5                                (1, 2)   \n",
       "\n",
       "  param_feats__text__tfidf__use_idf  \\\n",
       "0                             False   \n",
       "1                              True   \n",
       "2                             False   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'clf__alpha': 1.0, 'clf__fit_prior': True, 'f...           0.575601   \n",
       "1  {'clf__alpha': 1.0, 'clf__fit_prior': True, 'f...           0.597938   \n",
       "2  {'clf__alpha': 1.0, 'clf__fit_prior': True, 'f...           0.548110   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0           0.546392           0.560137         0.560710        0.011932   \n",
       "1           0.551546           0.587629         0.579038        0.019890   \n",
       "2           0.530928           0.532646         0.537228        0.007727   \n",
       "\n",
       "   rank_test_score  \n",
       "0               58  \n",
       "1               47  \n",
       "2              145  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Best params: {}'.format(nb_grid.best_params_))\n",
    "nb_cv_results = pd.DataFrame(nb_grid.cv_results_)\n",
    "nb_cv_results.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter text for estimator FeatureUnion(transformer_list=[('message',\n                                Pipeline(steps=[('selector',\n                                                 TextSelector(key='message')),\n                                                ('tfidf', TfidfVectorizer())])),\n                               ('neu_scores',\n                                Pipeline(steps=[('selector',\n                                                 NumberSelector(key='neu_scores')),\n                                                ('minmax', MinMaxScaler())])),\n                               ('neg_scores',\n                                Pipeline(steps=[('selector',\n                                                 NumberSelector(key='neg_scores')),\n                                                ('minmax', MinMaxScaler())])),\n                               ('pos_scores',\n                                Pipeline(steps=[('selector',\n                                                 NumberSelector(key='pos_scores')),\n                                                ('minmax', MinMaxScaler())])),\n                               ('compound_scores',\n                                Pipeline(steps=[('selector',\n                                                 NumberSelector(key='compound_scores')),\n                                                ('minmax', MinMaxScaler())]))]). Check the list of available parameters with `estimator.get_params().keys()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-65dacacc3f71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0msvm_grid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# end time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1188\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    706\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[1;32m    709\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1027\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    253\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    253\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0mcloned_parameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mcloned_parameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mset_params\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \"\"\"\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'steps'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m_set_params\u001b[0;34m(self, attr, **params)\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_replace_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;31m# 3. Step parameters and other initialisation arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mset_params\u001b[0;34m(self, **params)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_params\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnested_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m             \u001b[0mvalid_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0msub_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mset_params\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    855\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m         \"\"\"\n\u001b[0;32m--> 857\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'transformer_list'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    858\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m_set_params\u001b[0;34m(self, attr, **params)\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_replace_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;31m# 3. Step parameters and other initialisation arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mset_params\u001b[0;34m(self, **params)\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalid_params\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m                 raise ValueError('Invalid parameter %s for estimator %s. '\n\u001b[0m\u001b[1;32m    250\u001b[0m                                  \u001b[0;34m'Check the list of available parameters '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m                                  \u001b[0;34m'with `estimator.get_params().keys()`.'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid parameter text for estimator FeatureUnion(transformer_list=[('message',\n                                Pipeline(steps=[('selector',\n                                                 TextSelector(key='message')),\n                                                ('tfidf', TfidfVectorizer())])),\n                               ('neu_scores',\n                                Pipeline(steps=[('selector',\n                                                 NumberSelector(key='neu_scores')),\n                                                ('minmax', MinMaxScaler())])),\n                               ('neg_scores',\n                                Pipeline(steps=[('selector',\n                                                 NumberSelector(key='neg_scores')),\n                                                ('minmax', MinMaxScaler())])),\n                               ('pos_scores',\n                                Pipeline(steps=[('selector',\n                                                 NumberSelector(key='pos_scores')),\n                                                ('minmax', MinMaxScaler())])),\n                               ('compound_scores',\n                                Pipeline(steps=[('selector',\n                                                 NumberSelector(key='compound_scores')),\n                                                ('minmax', MinMaxScaler())]))]). Check the list of available parameters with `estimator.get_params().keys()`."
     ]
    }
   ],
   "source": [
    "# Support Vector Classifier\n",
    "\n",
    "# combine features\n",
    "features_count = features_union(tfidf)\n",
    "\n",
    "# instantiate pipeline\n",
    "svm_count_pipeline = Pipeline([('feats', features_count),  ('clf', LinearSVC())])\n",
    "\n",
    "# parameter grid (3x3x2x3x7x2) combinations\n",
    "parameters = {\n",
    "    'feats__text__tfidf__max_df': (0.5, 0.75, 1.0),\n",
    "    'feats__text__tfidf__ngram_range': ((1, 1), (1, 2), (2, 2)), \n",
    "    'feats__text__tfidf__use_idf': (False, True),\n",
    "    'clf__loss': ('hinge', 'squared_hinge'),\n",
    "    'clf__C': (0.1, 0.5, 0.6, 1, 4, 5, 10, 100),\n",
    "    'clf__class_weight': (None, 'balanced')                                    \n",
    "}\n",
    "\n",
    "# instantiate GridSearchCV object with pipeline and parameters with 3-folds cross-validation\n",
    "svm_grid = GridSearchCV(svm_count_pipeline, parameters, cv=3)\n",
    "\n",
    "# start time \n",
    "svm_start = time.time()\n",
    "\n",
    "# fit\n",
    "svm_grid.fit(X_train, y_train)\n",
    "\n",
    "# end time \n",
    "svm_end = time.time()\n",
    "print(f\"Time taken to run: {round((svm_end - svm_start)/60,1)} minutes\")\n",
    "\n",
    "# score\n",
    "svm_grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
